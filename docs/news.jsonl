{"query": "AI", "id": "2505.17021v1", "url": "http://arxiv.org/abs/2505.17021v1", "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "summary": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "authors": ["Sara Ghaboura", "Ketan More", "Wafa Alghallabi", "Omkar Thawakar", "Jorma Laaksonen", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "published_date": "2025-05-22", "title_zh": "ARB：一個全面的阿拉伯語多模態推理基準", "summary_zh": "大型多模態模型(LMMs)越來越強大，評估它們的推理過程也變得更加重要。但現有基準主要集中在英語，忽略了像阿拉伯語這樣具有豐富語言和文化背景的語言。為了解決這個問題，我們推出了全面的阿拉伯語多模態推理基準(ARB)，這是第一個旨在評估阿拉伯語文本和視覺模態中逐步推理的基準。ARB涵蓋11個不同的領域，包括視覺推理、文檔理解、OCR、科學分析和文化詮釋。它包含1,356個多模態樣本，並配有5,119個人工策劃的推理步驟和相應的操作。我們評估了12個最先進的開源和閉源LMMs，發現它們在連貫性、忠實性和文化基礎方面存在持續的挑戰。ARB提供了一個結構化的框架，用於診斷代表性不足語言中的多模態推理，並標誌著邁向包容、透明和具有文化意識的人工智能系統的關鍵一步。我們發布了基準、評分標準和評估套件，以支持未來的研究和可重複性。", "applications": ["**智慧教育：** 將教材圖片和文字結合，讓阿拉伯語學生在學習歷史或科學概念時，能透過模型的逐步推理，更深入理解知識點之間的關聯，例如分析古蘭經中的文本與圖像，輔助宗教研究。", "**智能客服：** 針對阿拉伯語用戶的圖文諮詢，模型可以理解用戶需求並逐步推理，提供更精確的產品建議或問題解答。例如，用戶上傳房屋照片並描述需求，模型可以分析照片風格和文字描述，推薦符合的室內設計方案。", "**新聞分析：** 模型可以分析阿拉伯語新聞文章中的文本和圖片，識別關鍵事件和人物，並根據阿拉伯文化背景進行深入解讀，例如分析政治漫畫中的隱喻和象徵意義。"], "pitch": "ARB基準是阿拉伯語多模態AI的敲門磚。現今LMMs在阿拉伯語理解和推理方面存在顯著差距，這意味著巨大的市場機會。ARB提供了一個客觀的評估標準和豐富的數據集，能加速相關技術的開發和商業化。想像一下，一個能深度理解阿拉伯文化的AI，在智慧教育、內容審核、商業洞察等領域都有著巨大潛力。我們正在打造一個充滿文化智慧的AI生態系統，早期投資將帶來豐厚回報。", "audio": "audios/2505.17021v1.mp3", "timestamp": "2025-05-24T15:19:40.770897"}
{"query": "Foundation Model", "id": "2505.16982v1", "url": "http://arxiv.org/abs/2505.16982v1", "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "published_date": "2025-05-22", "title_zh": "超越關聯性：邁向生物醫學領域的因果大型語言模型代理", "summary_zh": "本文探討如何讓大型語言模型（LLMs）在生物醫學領域具備真正的因果理解能力，而不僅僅依賴關聯性。我們設想一種因果LLM代理，能夠整合多模態數據（文字、圖像、基因組等），並進行基於介入的推理，以推斷因果關係。實現這一目標需要克服諸多挑戰，包括設計安全可控的代理框架、開發嚴格的因果評估基準、整合異質數據源，以及將LLM與結構化知識（知識圖譜）和形式化的因果推斷工具相結合。這種代理有潛力加速藥物發現、實現個人化醫療等變革性應用。本研究旨在促進跨學科合作，結合因果概念和基礎模型，為生物醫學進展開發可靠的AI夥伴。", "applications": ["**精準醫療診斷助手:** 醫生可利用AI分析病人的基因數據、病歷、影像等多模態數據，快速找出疾病的真正病因，制定更有效的治療方案。", "**新藥研發加速器:** AI能夠自動生成藥物作用機制的假設，並模擬藥物在人體內的反應，大幅縮短新藥研發週期，降低研發成本。", "**公共衛生政策模擬器:** 政府可利用AI模擬不同公共衛生政策（例如疫苗接種計劃）對疾病傳播的影響，預測潛在風險，制定更科學合理的政策。"], "pitch": "各位投資人，我們正處於生物醫學AI的黃金時代！現有LLM主要依賴關聯性分析，缺乏真正的因果理解，這限制了它們在生物醫學領域的應用。我們的團隊正在開發基於因果推理的LLM代理，這將是下一代AI的關鍵突破。想像一下，一個能夠預測藥物副作用、診斷罕見疾病、甚至預測公共衛生危機的AI。我們相信，這項技術將徹底改變藥物研發、臨床診斷和公共衛生管理，創造巨大的市場價值。我們不僅提供了一個AI工具，更提供了一個生物醫學領域的變革引擎，等待您的投資來驅動它！", "audio": "audios/2505.16982v1.mp3", "timestamp": "2025-05-24T15:19:59.989021"}
{"query": "Diffusion Model", "id": "2505.17013v1", "url": "http://arxiv.org/abs/2505.17013v1", "title": "When Are Concepts Erased From Diffusion Models?", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "published_date": "2025-05-22", "title_zh": "擴散模型中的概念何時被抹除？", "summary_zh": "概念抹除，也就是選擇性地阻止模型生成特定概念的能力，越來越受到關注。雖然出現了許多方法來應對這個挑戰，但這些方法究竟能多徹底地抹除目標概念仍然不明確。本研究提出了兩個關於擴散模型中抹除機制的概念模型：（一）降低生成目標概念的可能性，以及（二）干擾模型內部的引導機制。為了徹底評估一個概念是否真正從模型中抹除，我們引入了一系列獨立的評估方法，包括對抗攻擊、新穎的探測技術，以及對模型在抹除概念後生成替代方案的分析。我們的結果揭示了最小化副作用和保持對抗性提示的魯棒性之間的權衡。總體而言，我們的工作強調了對擴散模型中的抹除進行全面評估的重要性。", "applications": ["**內容審查與合規性：** 應用於防止生成涉及敏感主題、仇恨言論或侵犯版權的內容，例如自動過濾掉生成式 AI 中的不雅圖片或言論。", "**藝術風格遷移與商業品牌保護：** 允許用戶在模仿特定藝術家風格的同時，避免產生與該藝術家關聯的特定圖像或主題，保護品牌形象，防止AI生成不符品牌調性的內容。", "**數據增強與合成數據安全性：** 在生成用於訓練模型的合成數據時，可以抹除敏感資訊，例如人臉特徵、個人身份資料，保護隱私，同時保留數據的整體結構和特性。"], "pitch": "我們正在開發一種更可靠、可控的概念抹除技術，用於擴散模型。現有技術在抹除特定概念時存在副作用和容易被對抗攻擊繞過的問題。我們的研究揭示了抹除機制的本質，並提供了一套全面的評估框架。這使我們能夠構建更安全、更可定制的生成式AI。商業價值體現在多個方面：首先，它可以幫助企業更好地遵守內容合規法規，降低法律風險。其次，可以保護品牌形象，防止AI生成不符品牌調性的內容。最後，在數據增強和合成數據領域，可以安全地生成大量訓練數據，加速AI模型的開發和部署。我們將打造一個API平台，提供高效、穩定的概念抹除服務，目標是成為生成式AI安全領域的領導者。", "audio": "audios/2505.17013v1.mp3", "timestamp": "2025-05-24T15:20:24.507568"}
{"query": "AI", "id": "2505.17021v1", "url": "http://arxiv.org/abs/2505.17021v1", "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "summary": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "authors": ["Sara Ghaboura", "Ketan More", "Wafa Alghallabi", "Omkar Thawakar", "Jorma Laaksonen", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "published_date": "2025-05-22", "title_zh": "ARB：一個全面的阿拉伯語多模態推理基準", "summary_zh": "論文介紹了一個新的基準測試工具 ARB，用於評估大型多模態模型（LMMs）在阿拉伯語環境下的推理能力。現有的基準測試主要集中在英語，忽略了阿拉伯語等具有豐富語言和文化背景的語言。ARB 涵蓋了視覺推理、文檔理解、OCR、科學分析和文化詮釋等多個領域，包含1356個多模態樣本和5119個人工整理的推理步驟。研究團隊評估了12個最先進的LMMs，發現它們在連貫性、忠實性和文化基礎方面仍存在挑戰。ARB 提供了一個結構化的框架，用於診斷在代表性不足的語言中的多模態推理，並朝著包容性、透明性和具有文化意識的人工智慧系統邁出了重要一步。該基準、評分標準和評估套件已公開發布。", "applications": ["**智能客服：** 應用於理解阿拉伯語客戶的語音和圖像問題，提供更準確和文化的相關的回應，例如：識別客戶拍攝的水果照片，並用阿拉伯語回答關於水果營養和產地等問題。", "**文化遺產保護：** 幫助解讀阿拉伯語古籍文獻和文物圖片，促進文化遺產的數位化和研究。 例如，分析古蘭經手稿的圖片，並自動提取重要段落，進行翻譯和註釋。", "**教育應用：** 用於開發阿拉伯語的互動式學習工具，提供多模態的教學內容，例如：根據學生提交的阿拉伯語作文圖片，自動評估其語法、文法和風格，並提供個性化建議。"], "pitch": "ARB 作為首個專注於阿拉伯語多模態推理的基準，解決了市場上對於非英語環境下 AI 評估的巨大缺口。 我們將提供一套經過驗證的工具，幫助企業和研究機構開發更智能、更符合文化背景的阿拉伯語 AI 應用。 數據集的稀缺性和專業性構成天然壁壘，有利於佔領市場先機。 潛在的商業模式包括：基準測試服務、AI模型評估和優化諮詢、特定領域的阿拉伯語AI解決方案（如智能客服、教育、文化遺產保護等）。 隨著中東和北非地區AI市場的快速增長，ARB具有巨大的商業價值。", "audio": "audios/2505.17021v1.mp3", "timestamp": "2025-05-24T15:38:43.259354"}
{"query": "Foundation Model", "id": "2505.16982v1", "url": "http://arxiv.org/abs/2505.16982v1", "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "published_date": "2025-05-22", "title_zh": "超越關聯性：朝向生物醫學領域的因果大型語言模型代理", "summary_zh": "這篇論文探討了如何讓大型語言模型（LLMs）在生物醫學領域具備真正的因果理解能力，而不僅僅是依賴關聯性。它提出了因果LLM代理的概念，這些代理能整合多模態數據（文字、圖片、基因組等），並進行基於干預的推理來推斷因果關係。開發這種代理需要克服一些挑戰，例如設計安全可控的代理框架、建立嚴謹的因果評估基準、整合異質數據源，以及將LLMs與結構化知識（知識圖譜）和正式的因果推斷工具結合。這樣的代理有潛力帶來變革性的機會，例如加速藥物發現和實現個性化醫療。", "applications": ["**個性化藥物反應預測：** 根據病患的基因組、病史、生活習慣等多維度資料，預測他們對不同藥物的反應，避免無效治療或不良反應。", "**新型療法探索：** 通過模擬不同治療方案對疾病進程的影響，找出潛在的藥物靶點或干預策略，加速新藥研發和療法開發。", "**臨床決策輔助：** 協助醫生評估病患病情，提供更精確的診斷建議，並根據因果關係模型，預測不同治療方案的可能結果，輔助決策。"], "pitch": "我們正在開發新一代的AI藥物研發平台，核心是具備因果推理能力的大型語言模型。相較於目前僅能分析關聯性的AI，我們的技術能更準確地預測藥物效果，大幅縮短研發時程，降低失敗風險，並實現精準醫療。 我們預計能顯著提升藥物開發的成功率，為製藥公司帶來數十億美元的潛在收益。 這項技術的商業價值在於大幅降低研發成本，加速藥物上市，並且為患者提供更有效的治療方案。 想像一下，一個AI能精準預測病患對特定藥物的反應，避免無效治療，這將對醫療產業帶來革命性的影響。", "audio": "audios/2505.16982v1.mp3", "timestamp": "2025-05-24T15:38:58.221274"}
{"query": "Diffusion Model", "id": "2505.17013v1", "url": "http://arxiv.org/abs/2505.17013v1", "title": "When Are Concepts Erased From Diffusion Models?", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "published_date": "2025-05-22", "title_zh": "擴散模型中的概念何時會被抹除？", "summary_zh": "概念抹除，也就是選擇性地阻止模型生成特定概念的能力，正受到越來越多的關注。儘管出現了各種方法來應對這一挑戰，但這些方法究竟能多徹底地抹除目標概念仍然不明朗。本研究提出了兩個關於擴散模型中抹除機制的概念模型：（一）降低生成目標概念的可能性，以及（二）干擾模型內部的引導機制。為了全面評估一個概念是否真正從模型中被抹除，我們引入了一套獨立的評估方法，包括對抗性攻擊、新型探測技術，以及分析模型在抹除概念後的替代生成結果。研究結果揭示了最小化副作用和維持對抗性提示的穩健性之間的緊張關係。總體而言，我們的工作強調了在擴散模型中進行概念抹除時，全面評估的重要性。", "applications": ["**內容安全過濾：** 針對仇恨言論、暴力內容等敏感詞彙和圖像，從AI生成內容中徹底抹除，避免生成不當內容。", "**個性化產品設計：** 在設計過程中抹除特定的設計風格或品牌元素，例如，在生成Logo時避免與現有品牌過於相似，確保原創性。", "**醫療影像匿名化：** 在醫療影像數據集中，抹除人臉、紋身等個人識別信息，同時保留醫療診斷所需的關鍵特徵，保護患者隱私。"], "pitch": "各位投資人，想像一下，AI創作內容充斥著版權爭議、仇恨言論和侵犯隱私的風險。我們團隊的研究突破性地解決了這個問題，開發出能精準抹除AI模型中特定概念的技術。這不僅能確保內容安全合規，還能賦予AI更強大的可控性，催生出個性化定製和數據隱私保護的新應用。從內容審核到設計創新，再到醫療數據安全，我們的技術擁有廣闊的市場前景。我們需要您的投資，將這項技術商業化，引領下一代安全、可信賴的AI內容創作，成為AI時代的守門人，佔據市場領導地位。", "audio": "audios/2505.17013v1.mp3", "timestamp": "2025-05-24T15:39:20.981673"}
{"query": "AI", "id": "2505.17021v1", "url": "http://arxiv.org/abs/2505.17021v1", "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "summary": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "authors": ["Sara Ghaboura", "Ketan More", "Wafa Alghallabi", "Omkar Thawakar", "Jorma Laaksonen", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "published_date": "2025-05-22", "title_zh": "ARB：一個全面的阿拉伯語多模態推理基準", "summary_zh": "大型多模態模型（LMMs）越來越強大，評估其推理過程變得重要。但現有基準主要針對英語，忽略了阿拉伯語等具有豐富語言和文化背景的語言。為此，我們推出了全面的阿拉伯語多模態推理基準（ARB），這是第一個旨在評估阿拉伯語中跨文本和視覺模態逐步推理的基準。ARB涵蓋11個不同的領域，包括視覺推理、文檔理解、OCR、科學分析和文化詮釋。它包含1,356個多模態樣本，配有5,119個人工整理的推理步驟和相應的操作。我們評估了12個最先進的開源和閉源LMM，發現它們在連貫性、忠實性和文化基礎方面仍存在挑戰。ARB提供了一個結構化的框架，用於診斷代表性不足語言中的多模態推理，標誌著邁向包容性、透明和具有文化意識的AI系統的關鍵一步。我們發布了基準、評分標準和評估套件，以支持未來的研究和可重複性。", "applications": ["**自動阿拉伯語文檔審閱與摘要:** 自動理解並總結阿拉伯語的法律、科學或歷史文檔，並能解釋其背後的邏輯和文化含義，例如審核伊斯蘭教法相關合約。", "**視覺內容的阿拉伯語文化適配:** 能夠理解圖像或影片中的阿拉伯語文化元素，並根據目標受眾進行適當的修改或翻譯，例如將西方廣告翻譯成阿拉伯語時，確保符合當地文化規範。", "**阿拉伯語教材輔助教學:** 分析阿拉伯語教材中的圖片、文字，並提供逐步的解釋和推理，幫助學生更好地理解和掌握知識，例如解釋古蘭經或阿拉伯文學作品中的隱喻和文化背景。"], "pitch": "ARB是第一個針對阿拉伯語多模態推理的綜合性基準，解決了AI模型在理解阿拉伯語文化和上下文方面的巨大缺口。目前市場上缺乏有效的阿拉伯語AI解決方案，而ARB的出現將加速相關技術的發展，為企業提供在阿拉伯語市場開展業務的關鍵工具。投資ARB的相關研究和應用，將有助於開發出更智能、更可靠、更符合文化需求的AI產品，並在快速增長的阿拉伯語市場中獲得巨大的商業價值。我們正處於構建下一個十億用戶AI的風口浪尖，而阿拉伯語AI將是其中的重要一環。", "audio": "audios/2505.17021v1.mp3", "timestamp": "2025-05-24T16:01:24.302023"}
{"query": "Foundation Model", "id": "2505.16982v1", "url": "http://arxiv.org/abs/2505.16982v1", "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "published_date": "2025-05-22", "title_zh": "超越相關性：邁向生物醫學領域的因果大型語言模型代理", "summary_zh": "目前的大型語言模型雖然在生物醫學領域展現潛力，但缺乏真正的因果理解，主要依賴相關性。本文提出一個願景，設想具備因果理解能力的大型語言模型代理，它們能整合多模態數據（文本、圖像、基因組等），並執行基於干預的推理，以推斷因果關係。要實現這一目標，需要克服關鍵挑戰：設計安全、可控的代理框架；開發嚴格的因果評估基準；整合異質數據源；以及將大型語言模型與結構化知識（知識圖譜）和形式化的因果推理工具協同結合。這樣的代理可以釋放變革性的機會，包括通過自動化的假設生成和模擬加速藥物發現，並通過針對患者的因果模型實現個性化醫療。此研究議程旨在促進跨學科合作，將因果概念和基礎模型結合起來，從而開發出可靠的AI合作夥伴，推動生物醫學的進步。", "applications": ["**加速藥物發現：** AI 代理可以自動生成藥物開發的假設，並模擬藥物在不同生理環境下的作用，大幅縮短研發週期。", "**個性化醫療方案：** 根據患者的基因、生活習慣、病史等多維數據，建立個性化的因果模型，預測治療效果，制定更精準的醫療方案。", "**公共衛生政策模擬：** 在疫情爆發等緊急情況下，模擬不同干預措施（例如封鎖、疫苗接種）對疫情傳播的影響，為決策者提供科學依據。"], "pitch": "我們正在構建生物醫學領域的下一代AI引擎：因果大型語言模型代理。與傳統依賴相關性的AI不同，我們的技術能真正理解因果關係，從而做出更準確的預測和更合理的決策。想像一下，一種AI能夠自動發現新藥靶點，為每位患者量身定制治療方案，並在公共衛生危機中提供最佳干預策略。這不僅能大幅降低藥物研發成本，還能顯著提高治療效果，並為公共衛生安全提供強有力的保障。我們擁有一支跨學科的頂尖團隊，正在攻克關鍵技術挑戰，並已取得初步成果。 我們相信，這項技術具有巨大的市場潛力，將徹底改變生物醫學領域，為投資者帶來豐厚的回報。現在加入我們，一起開創生物醫學AI的未來！", "audio": "audios/2505.16982v1.mp3", "timestamp": "2025-05-24T16:01:42.349579"}
{"query": "Diffusion Model", "id": "2505.17013v1", "url": "http://arxiv.org/abs/2505.17013v1", "title": "When Are Concepts Erased From Diffusion Models?", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "published_date": "2025-05-22", "title_zh": "擴散模型中的概念何時被抹除？", "summary_zh": "概念抹除，也就是選擇性地阻止模型生成特定概念的能力，引起了越來越多的關注，並且出現了各種解決這個挑戰的方法。然而，這些方法抹除目標概念的徹底程度仍然不清楚。我們首先提出了兩個擴散模型中抹除機制的概念模型：(i) 降低生成目標概念的可能性，以及 (ii) 干擾模型內部的引導機制。為了徹底評估一個概念是否真正從模型中抹除，我們引入了一套獨立的評估方法。我們的評估框架包括對抗性攻擊、新穎的探測技術，以及對模型在抹除概念後產生的替代生成的分析。我們的結果揭示了最小化副作用和保持對對抗性提示的魯棒性之間的張力。總體而言，我們的研究強調了對擴散模型中的抹除進行全面評估的重要性。", "applications": ["**兒童安全內容生成：** 可以移除模型生成兒童不宜的內容，例如暴力、性暗示等，確保產出的影像適合兒童觀看，打造更安全的內容生態。", "**保護智慧財產權：** 移除模型生成涉及特定品牌或角色的內容，避免侵權行為，協助企業保護自己的智慧財產權。", "**醫療影像處理：** 在醫療影像中移除可能洩漏病人隱私的個人資訊或敏感區域，例如臉部、紋身等，在保護病人隱私的同時，也能進行影像分析和模型訓練。"], "pitch": "我們正在解決AI安全和道德的根本問題：如何可靠地從AI模型中移除特定概念，防止其產生有害或不當內容。現有的「概念抹除」方法效果不一，我們提供了更嚴格的評估標準和技術，確保抹除的徹底性。這項技術的商業價值在於：1. **合規性與信任：** 協助企業符合日益嚴格的AI監管要求，建立使用者對AI內容的信任。2. **降低風險：** 減少AI模型產生有害內容造成的法律責任和聲譽損害。3. **差異化競爭：** 為內容生成平台提供更安全、更可靠的服務，在市場上脫穎而出。我們正在尋求投資，以擴展我們的評估框架，開發更有效的抹除技術，並將其商業化，成為AI安全領域的領導者。", "audio": "audios/2505.17013v1.mp3", "timestamp": "2025-05-24T16:01:59.997130"}
{"query": "AI", "id": "2505.17021v1", "url": "http://arxiv.org/abs/2505.17021v1", "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "summary": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "authors": ["Sara Ghaboura", "Ketan More", "Wafa Alghallabi", "Omkar Thawakar", "Jorma Laaksonen", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "published_date": "2025-05-22", "title_zh": "ARB：一個全面的阿拉伯語多模態推理基準測試", "summary_zh": "本論文提出了一個名為 ARB 的全新基準測試，專門用於評估大型多模態模型 (LMM) 在阿拉伯語環境下的推理能力。現有基準測試大多集中在英語，忽略了像阿拉伯語這樣具有豐富語言和文化背景的語言。ARB 涵蓋視覺推理、文檔理解、光學字元識別、科學分析和文化詮釋等11個不同領域，包含1356個多模態樣本和5119個人工策劃的推理步驟。研究團隊評估了12個最先進的 LMM，發現它們在連貫性、忠實性和文化基礎方面仍存在挑戰。ARB 提供了一個結構化的框架，用於診斷在代表性不足的語言中的多模態推理能力，並標誌著邁向包容性、透明性和具有文化意識的 AI 系統的關鍵一步。研究團隊公開了基準測試、評分標準和評估工具，以支持未來的研究和可再現性。", "applications": ["**智能阿拉伯語教學系統：** 利用 ARB 訓練的 LMM 可以根據學生提供的文本和圖像，提供個性化的學習反饋，並解釋其中涉及的阿拉伯文化元素，從而提升學習效率和趣味性。", "**多語種文檔處理與翻譯：** 應用於大規模阿拉伯語文檔的自動翻譯，不僅能準確翻譯文字，還能理解圖像和圖表，並根據阿拉伯文化背景進行調整，確保翻譯結果更符合當地習慣。", "**智慧城市中的文化遺產保護：** 通過分析歷史圖片、文檔和地理數據，LMM 可以自動識別和保護阿拉伯世界的文化遺址，並生成互動式展覽內容，讓遊客更深入地了解當地歷史和文化。"], "pitch": "ARB 填補了大型多模態模型在阿拉伯語領域的評估空白，解決了目前 AI 模型缺乏文化理解和推理能力的問題。這個基準測試對於開發能夠有效處理阿拉伯語環境下文本和圖像的 AI 系統至關重要。基於 ARB 的技術具有廣泛的商業價值，例如提升阿拉伯語客戶服務的質量、加速阿拉伯語文檔的數位化進程，以及促進阿拉伯文化遺產的保護和傳播。通過投資基於 ARB 基準開發的 AI 解決方案，我們可以搶佔阿拉伯語多模態 AI 市場的先機，並在快速增長的阿拉伯數字經濟中獲得可觀的回報。", "audio": "audios/2505.17021v1.mp3", "timestamp": "2025-05-24T16:05:27.675474"}
{"query": "Foundation Model", "id": "2505.16982v1", "url": "http://arxiv.org/abs/2505.16982v1", "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "published_date": "2025-05-22", "title_zh": "超越相關性：邁向生物醫學領域的因果大型語言模型代理", "summary_zh": "這篇論文探討如何讓大型語言模型（LLMs）在生物醫學領域具備真正的因果理解能力，而不僅僅是仰賴相關性。作者設想一種因果LLM代理，它能整合多模態數據（文本、圖像、基因組數據等），並通過基於干預的推理來推斷因果關係。要實現這一目標，需要克服安全可控的代理框架設計、嚴格的因果評估基準開發、異構數據源整合，以及將LLMs與結構化知識（知識圖譜）和形式因果推理工具協同結合等挑戰。這種代理有望加速藥物發現、實現個性化醫療，並成為生物醫學研究中可靠的AI夥伴。", "applications": ["**藥物開發加速器：** 因果LLM代理可以自動生成和模擬藥物作用假設，大幅縮短藥物研發周期。", "**精準醫療專家：** 根據患者的個性化數據，構建個體化的因果模型，幫助醫生制定更有效的治療方案。", "**疾病風險預測工具：** 整合基因組、生活習慣等多維度數據，預測個體患病風險，提前進行預防干預。"], "pitch": "我們正在構建下一代生物醫學AI，它不僅僅是信息彙總工具，而是具備因果推理能力的智能代理。這將徹底改變藥物研發、個性化醫療和疾病預防等領域。試想一下，一個能夠自動發現新藥靶點、為每位患者量身定制治療方案的AI助手。我們需要資金來克服技術挑戰，建立可靠、安全的因果LLM代理，並将其商業化。回報將是巨大的：更快的藥物研發速度、更精準的醫療方案和更健康的社會。這不僅僅是一個投資，更是一次對未來醫療的佈局。", "audio": "audios/2505.16982v1.mp3", "timestamp": "2025-05-24T16:05:44.781587"}
{"query": "Diffusion Model", "id": "2505.17013v1", "url": "http://arxiv.org/abs/2505.17013v1", "title": "When Are Concepts Erased From Diffusion Models?", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "published_date": "2025-05-22", "title_zh": "擴散模型中的概念何時被抹除？", "summary_zh": "概念抹除，也就是選擇性地阻止模型生成特定概念的能力，正引起越來越多的關注，並出現了各種方法來應對這一挑戰。然而，這些方法究竟能多徹底地抹除目標概念，仍然不明朗。 本文首先針對擴散模型中的抹除機制提出了兩個概念模型：（i）降低生成目標概念的可能性，以及（ii）干擾模型的內部引導機制。 為了徹底評估一個概念是否真正從模型中被抹除，我們引入了一套獨立的評估方法。 我們的評估框架包括對抗性攻擊、新穎的探測技術，以及對模型在抹除概念後產生的替代性生成的分析。 我們的研究結果揭示了最小化副作用和保持對抗性提示的穩健性之間的權衡。 總體而言，我們的研究強調了對擴散模型中抹除效果進行全面評估的重要性。", "applications": ["**內容審查與保護：** 防止生成涉及暴力、仇恨言論或不適當內容的圖像，例如自動過濾掉兒童不宜的圖像或避免生成特定政治人物的虛假圖片。", "**個人化體驗優化：** 根據用戶偏好，動態過濾掉用戶不喜歡或觸發負面情緒的概念，例如在遊戲中移除特定敵人類型，或在廣告中排除特定品牌。", "**設計與創作控制：** 在設計過程中，移除設計師不希望出現的元素或風格，例如在建築設計中避免特定建築風格，或在產品設計中排除特定材料。"], "pitch": "我們解決的是AI生成內容領域的核心信任問題：如何有效控制模型的生成內容，避免產生有害、不適當或不符合需求的結果。我們的研究揭示了現有概念抹除方法的局限性，並提供了更全面的評估框架。這使得我們能夠開發更有效、更安全的AI生成工具，應用於內容審查、個人化體驗和創意設計等領域。想像一下，一個能夠完全受控的AI內容生成引擎，它能夠在滿足用戶需求的同時，有效避免產生有害內容，這將極大地提升AI在各行業的應用價值，並為我們帶來巨大的商業機會。", "audio": "audios/2505.17013v1.mp3", "timestamp": "2025-05-24T16:06:09.636884"}
{"query": "AI", "id": "2505.17021v1", "url": "http://arxiv.org/abs/2505.17021v1", "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "summary": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "authors": ["Sara Ghaboura", "Ketan More", "Wafa Alghallabi", "Omkar Thawakar", "Jorma Laaksonen", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "published_date": "2025-05-22", "title_zh": "ARB：一個全面的阿拉伯語多模態推理基準測試", "summary_zh": "大型多模態模型(LMM)越來越強大，評估其推理過程也變得重要。然而，大多數基準測試都集中在英語上，忽略了像阿拉伯語這樣具有豐富語言和文化背景的語言。因此，我們推出了一個全面的阿拉伯語多模態推理基準測試(ARB)，旨在評估阿拉伯語中跨文本和視覺模態的逐步推理。ARB涵蓋11個不同的領域，包括視覺推理、文檔理解、OCR、科學分析和文化解釋。它包含1,356個多模態樣本，並配有5,119個人工策劃的推理步驟和相應的動作。我們評估了12個最先進的開源和閉源LMM，發現它們在連貫性、忠實性和文化基礎方面仍然存在挑戰。ARB為診斷代表性不足的語言中的多模態推理提供了一個結構化的框架，並標誌著邁向包容、透明和具有文化意識的AI系統的關鍵一步。我們發布了基準、評分標準和評估套件，以支持未來的研究和可重複性。程式碼可在以下網址取得：https://github.com/mbzuai-oryx/ARB", "applications": ["**自動化阿拉伯語文獻分析：** 用於分析大量的阿拉伯語歷史文獻或科學論文，自動提取關鍵信息、識別論點，並理解其中的文化背景，例如分析古代手稿或現代阿拉伯科學文獻。", "**智能客服與教育：** 在阿拉伯語地區提供更準確、更貼近文化的智能客服，解決客戶問題，或者作為阿拉伯語學習工具，幫助學生理解複雜的文本和視覺信息，並解答與阿拉伯文化相關的問題。", "**內容審核與本地化：** 自動審核阿拉伯語社交媒體內容，識別仇恨言論、錯誤信息或不當內容，並確保內容符合當地文化和法律規範。此外，還可以提升英文內容翻譯成阿拉伯語的品質，確保翻譯結果在文化上準確且易於理解。"], "pitch": "ARB基準測試解決了目前AI模型在阿拉伯語多模態推理能力上的空白，擁有巨大的商業潛力。首先，它為開發更智能、更貼近阿拉伯文化的AI應用奠定了基礎，有助於打開中東和北非市場。其次，ARB可以加速各行各業的AI落地，例如文獻分析、客戶服務、教育和內容審核等，提升效率和降低成本。最後，ARB的數據集和評估工具本身就具有商業價值，可以授權給企業和研究機構使用，加速AI模型的開發和優化。我們相信，ARB將成為阿拉伯語AI領域的黃金標準，並為投資者帶來豐厚的回報。", "audio": "audios/2505.17021v1.mp3", "timestamp": "2025-05-24T16:15:03.736340"}
{"query": "Foundation Model", "id": "2505.16982v1", "url": "http://arxiv.org/abs/2505.16982v1", "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "published_date": "2025-05-22", "title_zh": "超越關聯性：邁向生物醫學領域的因果大型語言模型代理", "summary_zh": "這篇論文探討如何讓大型語言模型（LLMs）不只學習關聯性，而是真正理解生物醫學領域的因果關係。透過整合多模態數據（文字、圖片、基因組等），並進行干預式推理，研究人員希望打造能夠推斷因果關係的因果LLM代理。實現這個目標需要克服安全控制、嚴格評估、數據整合和知識融合等多項挑戰。這種因果LLM代理潛力巨大，例如能自動生成假設、模擬實驗，加速藥物發現，以及建立個人化的因果模型，實現精準醫療。", "applications": ["**輔助醫生診斷與治療：** LLM代理可以分析病人的病歷、影像報告和基因數據，找出疾病的根本原因，並推薦更有效的治療方案。", "**加速新藥開發：** LLM代理可以模擬藥物與人體作用，預測藥物效果和副作用，減少臨床試驗的成本和時間。", "**個人化健康管理：** LLM代理可以根據個人的生活習慣、基因數據和健康指標，提供客製化的健康建議和預防措施。"], "pitch": "想像一下，我們能打造一個像頂尖醫學專家一樣思考的人工智慧，它不只是記錄數據，更能理解疾病的真正原因，並針對每個病患提出最有效的治療方案。這就是我們正在開發的因果大型語言模型代理。這項技術的核心價值在於，它能加速新藥開發，降低臨床試驗成本，並推動個人化醫療的發展。我們將整合多模態數據、應用因果推理技術，並建立嚴謹的評估標準，確保AI的建議既安全又可靠。藥廠可以利用它來加速藥物研發流程；醫院可以用它來提升診斷準確性和治療效果；保險公司則可以利用它來提供更精準的風險評估和健康管理服務。我們相信，這項技術將徹底改變生物醫學領域，帶來巨大的經濟效益和社會價值，成為醫療領域的下一個重大突破。", "audio": "audios/2505.16982v1.mp3", "timestamp": "2025-05-24T16:15:22.280146"}
{"query": "Diffusion Model", "id": "2505.17013v1", "url": "http://arxiv.org/abs/2505.17013v1", "title": "When Are Concepts Erased From Diffusion Models?", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "published_date": "2025-05-22", "title_zh": "概念何時從擴散模型中被抹除？", "summary_zh": "概念抹除，即選擇性地阻止模型生成特定概念的能力，日益受到關注，也出現了各種方法來應對這個挑戰。然而，這些方法究竟能多徹底地抹除目標概念仍然不明朗。我們首先提出了兩個關於擴散模型中抹除機制的概念模型：（i）降低生成目標概念的可能性，以及（ii）干擾模型的內部引導機制。為了徹底評估一個概念是否真的從模型中被抹除，我們引入了一套獨立的評估方法。我們的評估框架包括對抗性攻擊、新型探測技術，以及對模型在抹除概念後產生的替代生成內容的分析。我們的結果揭示了最小化副作用和保持對抗性提示的穩健性之間的緊張關係。總的來說，我們的工作強調了對擴散模型中抹除操作進行全面評估的重要性。", "applications": ["**內容審查和安全:**  在AI圖像生成中，避免產生包含暴力、歧視或其他有害內容的圖像。例如，可以防止生成槍枝、炸彈或種族歧視相關圖像。", "**藝術風格保護:**  保護特定藝術家的風格不被濫用或抄襲。例如，可以防止他人使用AI生成類似梵谷或莫內的風格的圖像，用於商業用途。", "**個人隱私保護:**  在生成人臉圖像時，抹除特定人物的身份信息，避免洩漏個人隱私。例如，在AI生成人像照片的應用中，避免生成與真實人物太過相似的圖像。"], "pitch": "概念抹除技術解決了AI生成模型中內容安全和知識產權保護的關鍵問題。透過精準控制AI模型的生成能力，我們可以打造更安全、更可信賴的AI應用生態。我們的研究提供了一套嚴謹的評估框架，確保概念抹除的有效性和安全性。這為開發具有高度可控性和道德性的AI產品奠定了基礎。想像一下，一個能夠在保護用戶免受有害內容侵害的同時，尊重藝術家權益並維護個人隱私的AI平台，這將帶來巨大的商業價值，並在內容創作、數據安全和品牌保護等領域開闢新的市場機會。我們的技術有潛力成為下一代AI應用的核心安全組件，吸引對AI安全性和責任性有高度要求的企業和政府機構。", "audio": "audios/2505.17013v1.mp3", "timestamp": "2025-05-24T16:15:48.266543"}
{"query": "AI", "id": "2505.17021v1", "url": "http://arxiv.org/abs/2505.17021v1", "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "summary": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "authors": ["Sara Ghaboura", "Ketan More", "Wafa Alghallabi", "Omkar Thawakar", "Jorma Laaksonen", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "published_date": "2025-05-22", "title_zh": "ARB：一個全面的阿拉伯語多模態推理基準", "summary_zh": "大型多模態模型越來越強大，但現有基準主要集中在英語，忽略了阿拉伯語等具有豐富語言和文化背景的語言。為此，我們推出了「ARB：全面的阿拉伯語多模態推理基準」，這是首個評估阿拉伯語文本和視覺模態逐步推理的基準。 ARB涵蓋11個領域，包括視覺推理、文檔理解、OCR、科學分析和文化詮釋。我們評估了12個領先的LMM模型，發現它們在連貫性、忠實度和文化基礎方面仍然存在挑戰。 ARB提供了一個結構化的框架，用於診斷代表性不足語言的多模態推理，並標誌著邁向包容、透明和具有文化意識的AI系統的關鍵一步。", "applications": ["**智能教育：** 根據阿拉伯文化背景，自動批改阿拉伯語教材中的多模態作業，例如分析學生對歷史圖片或詩歌的理解，並提供個性化的反饋和學習建議。", "**文化遺產保護：** 幫助研究人員分析古代阿拉伯文稿和文物圖片，自動識別關鍵信息、推斷歷史事件，並對文物進行分類和記錄，加速文化遺產的數位化保存。", "**金融風險評估：** 分析阿拉伯語新聞、社交媒體文章和財務報告，結合圖像信息（如建築外觀、產品圖片）來評估企業的信譽和潛在風險，從而輔助投資決策。"], "pitch": "ARB基準的推出，解決了AI領域長期以來忽視阿拉伯語及阿拉伯文化背景的問題，填補了多模態推理能力評估的空白。這不僅能幫助提升現有LMM在阿拉伯語環境下的表現，更為開發面向阿拉伯世界的AI應用奠定了基礎。我們相信，基於ARB基準訓練出的AI模型，將在教育、文化遺產保護、金融等領域產生巨大的商業價值，並有望推動阿拉伯地區的數位化轉型。未來，我們可以通過提供基於ARB基準的AI服務、開發垂直領域的解決方案，例如針對阿拉伯語教育的AI輔導工具、針對阿拉伯文化遺產的AI分析平台，實現可持續的商業模式，並且搶佔中東及北非地區的AI市場先機。", "audio": "audios/2505.17021v1.mp3", "timestamp": "2025-05-24T18:16:44.387956"}
{"query": "Foundation Model", "id": "2505.16982v1", "url": "http://arxiv.org/abs/2505.16982v1", "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "published_date": "2025-05-22", "title_zh": "超越關聯性：邁向生物醫學領域的因果大型語言模型代理", "summary_zh": "目前的大型語言模型在生物醫學領域展現潛力，但缺乏真正的因果理解，僅依賴相關性。本研究旨在打造因果大型語言模型代理，整合多模態資料（文本、圖像、基因組等），並執行基於干預的推理來推斷因果關係。這需要克服設計安全可控的代理框架、開發嚴謹的因果評估基準、整合異構資料來源，以及將大型語言模型與結構化知識（知識圖譜）和正式因果推理工具結合等挑戰。這些代理有望通過自動化假設生成和模擬加速藥物發現，並通過患者特定的因果模型實現個性化醫療。本研究旨在促進跨學科合作，橋接因果概念和基礎模型，為生物醫學進展開發可靠的人工智慧夥伴。", "applications": ["**加速新藥開發：** 模擬不同藥物組合對特定疾病的影響，預測藥物療效，並找出潛在副作用，從而縮短研發時程，降低成本。", "**個性化精準醫療：** 根據病患的基因、生活習慣等個人資料，建立個人化的因果模型，預測疾病風險，並提供量身定制的治療方案，提高治療效果。", "**輔助臨床決策：** 分析病患的醫療數據，找出關鍵致病因素，協助醫生進行更準確的診斷，並制定最佳治療策略。"], "pitch": "想像一下，一個能夠理解因果關係的人工智慧，它不再只是分析數據，而是能夠主動找出疾病的真正原因，預測治療效果，甚至幫助科學家們發現全新的藥物。我們正在開發的因果大型語言模型代理，正是這樣一個突破性的技術。它整合了多模態的生物醫學數據，運用先進的因果推理方法，為藥物開發、個性化醫療和臨床決策帶來革命性的改變。這個技術的商業價值巨大，可以加速藥物上市，降低醫療成本，提高治療效果，最終改善人類健康。我們正在尋找有遠見的投資者，一同打造這個未來醫療的核心引擎。", "audio": "audios/2505.16982v1.mp3", "timestamp": "2025-05-24T18:17:00.816672"}
{"query": "Diffusion Model", "id": "2505.17013v1", "url": "http://arxiv.org/abs/2505.17013v1", "title": "When Are Concepts Erased From Diffusion Models?", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "published_date": "2025-05-22", "title_zh": "擴散模型何時會抹除概念？", "summary_zh": "概念抹除，也就是選擇性地阻止模型生成特定概念的能力，正受到越來越多的關注。雖然已經出現了多種方法來解決這個問題，但這些方法究竟能多徹底地抹除目標概念仍然不明確。本研究提出了兩個關於擴散模型中抹除機制的概念模型：（一）降低生成目標概念的可能性，以及（二）干擾模型的內部指導機制。為了徹底評估一個概念是否真的從模型中被抹除，我們引入了一套獨立的評估方法。我們的評估框架包括對抗性攻擊、新型探測技術，以及對模型替代生成（代替被抹除概念）的分析。研究結果揭示了最小化副作用和保持對抗性提示的穩健性之間的張力。總體而言，我們的工作強調了對擴散模型中抹除進行全面評估的重要性。", "applications": ["**內容過濾與審查：** 自動從圖像或文本生成中移除不適當或敏感的內容，例如仇恨言論、暴力內容或個人資訊，以符合平台的內容規範。", "**藝術風格轉移控制：** 在進行藝術風格轉移時，可以選擇性地抹除某些風格元素，例如，避免將敏感政治人物的特徵融合到藝術作品中。", "**數據增強中的偏差移除：** 在使用擴散模型生成數據以訓練其他模型時，可以抹除數據中的偏差（例如性別或種族偏見），從而提高下游模型的公平性。"], "pitch": "我們發現了現有擴散模型「概念抹除」技術的盲點，並開發了一套更全面的評估框架。這項技術的核心價值在於精確控制 AI 生成內容的能力，允許在不犧牲模型生成能力的同時，移除特定概念。這在內容審查、藝術風格轉移控制、以及數據增強等多個領域具有廣泛的應用前景。我們的商業模式可以是：\n\n*   **提供API服務：** 為需要內容過濾或數據淨化的企業提供基於我們的概念抹除技術的API服務，按使用量或訂閱收費。\n*   **授權技術：** 將我們的技術授權給大型科技公司或研究機構，用於改進他們的AI模型。\n*   **開發垂直應用：** 針對特定領域（例如醫療影像、金融數據）開發專業的概念抹除工具，提供給相關行業的客戶。\n\n我們的優勢在於我們對概念抹除的深入理解和全面的評估方法，能確保抹除的有效性和安全性，避免不必要的副作用。這將使我們的解決方案在市場上具有競爭力，並帶來可觀的商業回報。", "audio": "audios/2505.17013v1.mp3", "timestamp": "2025-05-24T18:17:18.228241"}
{"query": "AI", "id": "2505.17021v1", "url": "http://arxiv.org/abs/2505.17021v1", "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "summary": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "authors": ["Sara Ghaboura", "Ketan More", "Wafa Alghallabi", "Omkar Thawakar", "Jorma Laaksonen", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "published_date": "2025-05-22", "title_zh": "ARB：一個全面的阿拉伯語多模態推理基準測試", "summary_zh": "我們推出了一個名為ARB的綜合阿拉伯語多模態推理基準測試，旨在評估大型多模態模型（LMM）在阿拉伯語環境下，結合文本和視覺信息進行逐步推理的能力。該基準涵蓋11個不同領域，包含1356個多模態樣本，並搭配5119個人工策劃的推理步驟。我們評估了12個最先進的LMM，發現它們在連貫性、真實性和文化基礎方面仍然存在挑戰。ARB提供了一個結構化的框架，用於診斷在代表性不足的語言中的多模態推理，標誌著邁向包容、透明和具有文化意識的人工智能系統的關鍵一步。我們已釋出該基準測試、評分標準和評估工具包。", "applications": ["**智慧教育：** 根據阿拉伯語教材的圖片和文本，自動生成逐步的解題過程和講解，幫助學生更好地理解知識。", "**文化遺產保護：** 識別和分析阿拉伯世界的歷史文獻、藝術品和建築，提供更準確和深入的文化背景解讀。", "**跨文化交流：** 輔助翻譯和理解阿拉伯文化相关的多模态信息，例如阿拉伯美食的食谱、节日习俗的说明等，消除跨文化交流的障碍。"], "pitch": "ARB是首個專為阿拉伯語設計的多模態推理基準測試，解决了现有LMM在非英语环境，特别是阿拉伯语文化理解上的短板。這使得LMM可以在更廣泛的全球市場中應用，尤其是在中東和北非地區。其潛在商業價值體現在以下幾個方面：\n\n* **市場差異化：** 能够理解和处理阿拉伯语多模态信息的LMM，相比竞争对手具有显著的优势，能够抢占市场先机。\n* **特定领域应用：** 在教育、文化、旅游等领域，ARB可以帮助开发更智能、更贴合本地需求的应用，例如个性化教育、文化遗产数字化、智能旅游导览等。\n* **数据增值：** ARB本身就是一个有价值的数据集，可以用于进一步训练和改进LMM，并可通过授权使用或提供API服务等方式实现商业化。\n* **解决实际痛点：** ARB有助于解决目前LMM在处理复杂阿拉伯语场景时遇到的问题，例如宗教典籍解读、古籍数字化、文化理解等，具有重要的社会价值和商业潜力。因此，投資ARB及其衍生應用具有高度的商業回報。", "audio": "audios/2505.17021v1.mp3", "timestamp": "2025-05-24T19:10:10.976557"}
{"query": "Foundation Model", "id": "2505.16982v1", "url": "http://arxiv.org/abs/2505.16982v1", "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "published_date": "2025-05-22", "title_zh": "超越關聯性：邁向生物醫學領域的因果大型語言模型代理", "summary_zh": "這篇論文探討大型語言模型（LLM）在生物醫學的應用，但指出它們目前僅依賴關聯性而非真正的因果理解。論文提出一個願景，打造能整合多模態數據（文本、圖像、基因組等），並進行干預式推理以推斷因果關係的因果LLM代理。這需要克服許多挑戰，包括設計安全可控的代理框架，建立嚴謹的因果評估基準，整合異構數據源，以及結合LLM與結構化知識（知識圖譜）和正式的因果推論工具。這些代理有望帶來變革性機會，例如通過自動化假設生成和模擬來加速藥物發現，以及通過患者特定的因果模型來實現個性化醫療。", "applications": ["**藥物靶點發現加速：** 利用因果LLM代理分析大量生物醫學數據，識別更精準的藥物靶點，從而加速新藥研發，降低研發成本。", "**個性化醫療方案制定：** 整合患者的基因組、病史、生活習慣等多模態數據，建立個體化的因果模型，預測不同治療方案的效果，制定更有效的個性化醫療方案。", "**疾病傳播預測與控制：** 透過分析疫情相關數據（地理位置、人口密度、病毒變異等），建構疾病傳播的因果模型，預測疾病爆發的趨勢和熱點地區，為公共衛生決策提供更科學的依據。"], "pitch": "想像一下，一個AI夥伴可以像資深研究員一樣，從海量的生物醫學數據中挖掘出隱藏的因果關係，加速藥物開發，優化醫療決策。我們提出的因果LLM代理正是這樣一個變革性的工具。它不僅能分析數據，更能理解數據背後的因果邏輯，實現真正的智能決策。市場潛力巨大，從加速藥物研發，到實現個性化醫療，再到預測疾病傳播，每個領域都充滿了商業機會。我們需要投資，將這個願景變成現實，在生物醫學領域掀起一場AI驅動的革命。", "audio": "audios/2505.16982v1.mp3", "timestamp": "2025-05-24T19:10:25.728425"}
{"query": "Diffusion Model", "id": "2505.17013v1", "url": "http://arxiv.org/abs/2505.17013v1", "title": "When Are Concepts Erased From Diffusion Models?", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "published_date": "2025-05-22", "title_zh": "擴散模型中的概念何時被抹除？", "summary_zh": "概念抹除，即選擇性地阻止模型生成特定概念的能力，正受到越來越多的關注。雖然出現了各種方法來應對這個挑戰，但這些方法到底能多徹底地抹除目標概念仍然不明朗。本研究首先提出兩個擴散模型中抹除機制的概念模型：（i）降低生成目標概念的可能性，以及（ii）干擾模型的內部引導機制。為了徹底評估一個概念是否真的從模型中被抹除，我們引入了一套獨立的評估方法，包括對抗性攻擊、新穎的探測技術，以及對模型在抹除概念後生成替代內容的分析。我們的結果揭示了最小化副作用和保持對對抗性提示的魯棒性之間的權衡。總體而言，我們的研究強調了對擴散模型中的抹除進行全面評估的重要性。", "applications": ["**内容审查与品牌安全：** 避免生成包含敏感信息或有害内容的图像，例如仇恨言论、虚假新闻、以及侵犯品牌版权的图像。", "**个性化教育内容生成：** 针对特定学习需求，屏蔽不相关的或超出当前学习范围的概念，集中生成目标知识点的相关图像，辅助教学。", "**艺术风格控制与创意工具：** 允許用户在生成图像时排除特定艺术风格或元素，例如“不要生成毕加索风格的猫”，从而更精细地控制生成结果，提升创意自由度。"], "pitch": "各位投資人，我們正在解決生成式 AI 領域一個日益重要的問題：如何安全且可控地使用 AI 生成内容。我們的研究深入探討了擴散模型中概念抹除的技術，並建立了一套嚴謹的評估框架，可以驗證特定概念是否真正從模型中被移除。這項技術的商業潛力巨大，它可以應用於内容审查、品牌安全、教育、以及創意工具等多個領域。 想像一下，一家公司可以利用我們的技術，確保其 AI 生成的廣告素材不會包含任何違規或不當的元素，從而避免法律風險和品牌聲譽的損失。 教育平台可以客製化生成學習內容，排除不必要的資訊，提升學習效率。 此外，我們的研究成果也為開發更安全、更可靠的生成式 AI 產品奠定了基礎。 我們相信，這項技術將成為下一代 AI 平台的關鍵组成部分，具有高度的投資價值。", "audio": "audios/2505.17013v1.mp3", "timestamp": "2025-05-24T19:10:40.149070"}
{"query": "AI", "id": "2505.17021v1", "url": "http://arxiv.org/abs/2505.17021v1", "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "summary": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "authors": ["Sara Ghaboura", "Ketan More", "Wafa Alghallabi", "Omkar Thawakar", "Jorma Laaksonen", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "published_date": "2025-05-22", "title_zh": "ARB：一個全面的阿拉伯語多模態推理基準測試", "summary_zh": "大型多模態模型（LMMs）越來越強大，評估它們的推理過程變得至關重要。但現有基準測試大多以英語為主，忽略了像阿拉伯語這樣具有豐富語言和文化背景的語言。我們推出了ARB，首個專為評估阿拉伯語文本和視覺多模態推理的基準測試。ARB涵蓋視覺推理、文檔理解、OCR、科學分析和文化詮釋等11個不同領域，包含1,356個多模態樣本，並配有5,119個人工整理的推理步驟和相應操作。我們評估了12個最先進的開放和閉源LMMs，發現它們在連貫性、忠實性和文化基礎方面仍然面臨挑戰。ARB提供了一個結構化的框架，用於診斷代表性不足的語言中的多模態推理，並標誌著邁向包容、透明和具有文化意識的AI系統的關鍵一步。我們發布了基準測試、評分標準和評估工具，以支持未來的研究和可重複性。", "applications": ["**文化遺產保存：** 自動分析阿拉伯古籍和文物圖像，理解其歷史背景和文化意義，並生成易於理解的解釋和描述，輔助文物修復和教育。", "**醫療診斷輔助：** 結合阿拉伯語病歷文本和醫學影像（如X光片），協助醫生進行更準確的診斷，尤其是在缺乏足夠醫療資源的地區。", "**智慧城市管理：** 通過分析阿拉伯語社交媒體文本和監控視頻，了解城市居民的需求和問題，並提供及時的公共服務和信息。"], "pitch": "ARB基準測試解決了阿拉伯語多模態AI發展的關鍵瓶頸。現有的多模態模型在阿拉伯語環境下的推理能力不足，限制了其在文化、醫療、教育等領域的應用。ARB提供了一個標準化的評估框架，能夠有效提升模型的性能，並吸引更多開發者和研究者投入阿拉伯語AI領域。這將帶來巨大的商業價值：\n\n*   **市場潛力巨大：** 中東和北非地區的阿拉伯語使用者眾多，對本地化AI解決方案需求旺盛。\n*   **技術壁壘高：** 阿拉伯語的複雜性和文化背景需要專門的解決方案，不易被通用模型替代。\n*   **商業模式多樣：** 可通過模型授權、定制開發、雲服務等方式實現商業化。我們將基於ARB構建領先的阿拉伯語多模態AI平台，搶占市場先機，並與政府、企業和學術機構建立廣泛合作，共同推動阿拉伯語AI的發展。", "audio": "audios/2505.17021v1.mp3", "timestamp": "2025-05-24T20:14:07.902784"}
{"query": "Foundation Model", "id": "2505.16982v1", "url": "http://arxiv.org/abs/2505.16982v1", "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "published_date": "2025-05-22", "title_zh": "超越關聯性：邁向生物醫學領域的因果大型語言模型代理", "summary_zh": "大型語言模型在生物醫學領域展現潛力，但缺乏真正的因果理解，僅仰賴關聯性。本文設想一種因果大型語言模型代理，整合多模態數據（文本、圖像、基因組等），並進行基於干預的推理來推斷因果關係。實現這一目標需要克服設計安全可控的代理框架、開發嚴格的因果評估基準、整合異質數據源，以及將大型語言模型與結構化知識（知識圖譜）和正式的因果推論工具協同結合等關鍵挑戰。這種代理有望釋放變革性機會，包括通過自動假設生成和模擬加速藥物發現，以及通過患者特定的因果模型實現個性化醫療。本研究旨在促進跨學科合作，將因果概念和基礎模型聯繫起來，為生物醫學的進步開發可靠的AI夥伴。", "applications": ["醫生診斷輔助：整合病患病歷、影像和基因數據，基於因果推理預測最佳治療方案，減少誤診率。", "藥物研發加速：通過模擬不同藥物對人體的因果影響，篩選有潛力的候選藥物，降低研發成本。", "公共衛生政策制定：模擬不同政策干預對疾病傳播的因果影響，為政府提供科學的決策依據。"], "pitch": "我們正在開發基於因果推理的生物醫學大型語言模型代理，這將徹底改變醫療保健和藥物研發領域。與傳統模型僅關注數據關聯性不同，我們的技術能夠理解因果關係，從而實現更準確的預測、更有效的治療方案和更快速的藥物發現。想像一下，一個 AI 醫生能夠整合所有病患數據，不僅僅是找到相似的病例，而是真正理解導致疾病的原因，從而做出最佳的診斷和治療建議。在藥物研發方面，我們的平台能夠模擬藥物在人體內的影響，大幅縮短臨床試驗時間，降低研發成本。這項技術的商業價值巨大，可以通過向醫院、藥廠和研究機構提供訂閱服務來實現盈利。我們相信，我們的因果大型語言模型代理將成為生物醫學領域的遊戲規則改變者，為投資者帶來豐厚的回報。", "audio": "audios/2505.16982v1.mp3", "timestamp": "2025-05-24T20:14:23.586096"}
{"query": "Diffusion Model", "id": "2505.17013v1", "url": "http://arxiv.org/abs/2505.17013v1", "title": "When Are Concepts Erased From Diffusion Models?", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "published_date": "2025-05-22", "title_zh": "擴散模型中的概念何時被抹除？", "summary_zh": "概念抹除，也就是選擇性地阻止模型生成特定概念的能力，越來越受關注。雖然湧現了許多方法來解決這個挑戰，但這些方法究竟能多徹底地抹除目標概念仍然不明朗。我們提出了兩種擴散模型中抹除機制的概念模型：（一）降低生成目標概念的可能性；（二）干擾模型內部的引導機制。為了徹底評估一個概念是否真正從模型中被抹除，我們引入了一套獨立的評估方法，包括對抗性攻擊、新穎的探測技術，以及分析模型在抹除概念後生成的替代方案。我們的結果揭示了最小化副作用與保持對抗性提示的魯棒性之間的張力。總體而言，我們的工作強調了全面評估擴散模型中概念抹除的重要性。", "applications": ["**內容審查與合規性：** 用於自動移除不當內容（例如仇恨言論、暴力圖像）或敏感資料（例如個人資料、機密商業資訊），確保生成內容符合法規與道德規範。", "**客製化藝術創作：** 允許使用者要求模型避免生成特定元素或風格，從而創造出更符合個人喜好的獨特藝術作品，例如要求AI畫作中不要出現特定品牌標誌或政治符號。", "**智慧財產權保護：** 防止AI模型生成與現有版權內容過於相似的圖像，降低侵權風險。 例如，讓遊戲公司確保AI生成的角色造型不侵犯其他遊戲的角色版權。"], "pitch": "這項研究解決了擴散模型中一個關鍵的挑戰：概念抹除。 想像一下，一個AI可以根據你的指示，聰明地避免生成任何你不想要的東西。這不僅僅是技術，更是一種責任。目前AI生成的內容可能涉及侵權、敏感資訊洩露等問題。我們的技術提供了一個強大的工具，可以精準控制AI的生成行為，大幅降低這些風險。我們可以將這項技術授權給內容平台、遊戲公司、廣告商等，幫助他們建立更安全、更合規、更具創意的AI應用。 我們提供的不僅僅是技術，而是一個更值得信賴的AI生態系統。 這是一個潛力無限的市場，現在加入正是時候。", "audio": "audios/2505.17013v1.mp3", "timestamp": "2025-05-24T20:14:37.608123"}
{"query": "AI", "id": "2505.17021v1", "url": "http://arxiv.org/abs/2505.17021v1", "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "summary": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "authors": ["Sara Ghaboura", "Ketan More", "Wafa Alghallabi", "Omkar Thawakar", "Jorma Laaksonen", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "published_date": "2025-05-22", "title_zh": "ARB：一個全面的阿拉伯語多模態推理基準", "summary_zh": "大型多模態模型（LMMs）的能力日益增強，人們越來越關注評估其推理過程。然而，大多數基準測試仍然側重於英語，忽略了像阿拉伯語這樣具有豐富語言和文化背景的語言。為了解決這個問題，我們推出了全面的阿拉伯語多模態推理基準（ARB），這是第一個旨在評估阿拉伯語文本和視覺模態中逐步推理的基準。ARB 涵蓋 11 個不同的領域，包括視覺推理、文檔理解、OCR、科學分析和文化詮釋。它包含 1,356 個多模態樣本，並配有 5,119 個人工管理的推理步驟和相應的操作。我們評估了 12 個最先進的開源和閉源 LMM，發現它們在連貫性、忠實性和文化基礎方面仍然存在挑戰。ARB 提供了一個結構化的框架，用於診斷代表性不足的語言中的多模態推理，並標誌著朝著包容、透明和具有文化意識的 AI 系統邁出的關鍵一步。我們發布基準、評分標準和評估套件，以支持未來的研究和可重複性。", "applications": ["**阿拉伯語文檔智能處理：** 自動處理阿拉伯語文檔，例如合同、發票和法律文件，提取關鍵資訊並進行風險評估，例如辨識條款中的文化敏感性，避免誤解和法律風險。", "**阿拉伯文化內容創作與審核：** 輔助生成符合阿拉伯文化規範的內容，例如廣告文案、新聞報導和教育材料，並自動審核現有內容，確保其不違反當地法律法規和社會習俗。", "**多語言教育與文化交流：** 開發基於阿拉伯語的沉浸式學習體驗，例如通過分析圖像和文本，提供阿拉伯歷史、藝術和文化的深入理解。例如，分析古蘭經經文，並結合相關歷史圖片，幫助學習者理解經文的背景和意義。"], "pitch": "ARB作為首個針對阿拉伯語多模態推理的綜合性基準，解決了LLM在阿拉伯語環境下的文化理解與應用瓶頸。其潛在商業價值巨大，體現在：\n\n1. **數據稀缺性：** 提供高質量、人工標注的阿拉伯語多模態數據集，為企業開發針對阿拉伯市場的AI產品提供寶貴的訓練資源，降低研發成本。\n2. **行業應用廣泛：** 可應用於金融、法律、教育、媒體等領域，提升阿拉伯語文檔處理、內容創作與審核、文化交流等方面的效率與準確性。\n3. **市場先發優勢：** 在阿拉伯語AI市場尚不成熟的階段，率先推出基於ARB的解決方案，能夠迅速佔領市場份額，建立競爭優勢。\n4. **技術壁壘：** ARB的開發需要深厚的阿拉伯語語言學、文化背景以及AI技術積累，形成較高的技術壁壘，不易被競爭對手模仿。\n\n總而言之，ARB不僅是學術研究的貢獻，更是unlock阿拉伯AI市場的鑰匙，具有巨大的商業潛力，值得投資。", "audio": "audios/2505.17021v1.mp3", "timestamp": "2025-05-24T21:12:11.116700"}
{"query": "Foundation Model", "id": "2505.16982v1", "url": "http://arxiv.org/abs/2505.16982v1", "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "published_date": "2025-05-22", "title_zh": "超越關聯性：邁向生物醫學領域的因果大型語言模型代理", "summary_zh": "這篇論文探討如何開發具備因果推理能力的生物醫學大型語言模型代理。現有的大型語言模型主要依賴關聯性，缺乏真正的因果理解。作者提出整合多模態數據（文本、圖像、基因組等），並進行基於干預的推理，來推斷因果關係的設想。開發這種代理需要克服一些挑戰，包括設計安全可控的框架、建立嚴格的因果評估標準、整合異構數據源，以及將大型語言模型與結構化知識（知識圖譜）和正式的因果推理工具結合。這種代理有望在生物醫學領域帶來變革，例如加速藥物發現，實現個性化醫療等。", "applications": ["**藥物副作用預測：**根據患者的基因、生活習慣和用藥歷史，預測某種藥物可能產生的副作用，幫助醫生選擇更安全的治療方案。", "**疾病診斷輔助：**整合病人的病歷、影像報告和基因數據，協助醫生診斷病因複雜的疾病，提高診斷準確性。", "**健康生活方式建議：**分析個人的生理數據和飲食習慣，提供個性化的健康建議，預測不同生活方式選擇對健康狀況的長期影響。"], "pitch": "想像一下，一個能像頂尖醫生一樣思考的AI助手，它不僅能讀懂醫學文獻，更能理解疾病的真正成因，並預測治療效果。我們正在開發的因果大型語言模型代理，將徹底改變生物醫學領域的研究和應用。它能加速藥物開發，降低研發成本，並根據個體差異提供個性化的醫療方案，大幅提升治療效果。這項技術的潛在市場規模巨大，涵蓋藥物研發、診斷試劑、個性化醫療等領域。我們相信，這項技術將為人類健康帶來前所未有的改善，並為投資者帶來豐厚的回報。目前，我們正尋求資金支持，用於建立完善的數據平台、開發高性能的因果推理算法，以及進行臨床驗證。加入我們，一起開創生物醫學AI的未來！", "audio": "audios/2505.16982v1.mp3", "timestamp": "2025-05-24T21:12:38.594655"}
{"query": "Diffusion Model", "id": "2505.17013v1", "url": "http://arxiv.org/abs/2505.17013v1", "title": "When Are Concepts Erased From Diffusion Models?", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "published_date": "2025-05-22", "title_zh": "擴散模型中的概念何時被抹除？", "summary_zh": "概念抹除，即有選擇地阻止模型生成特定概念的能力，越來越受到關注，並湧現出各種方法來應對這一挑戰。然而，這些方法究竟能多麼徹底地抹除目標概念仍不明朗。我們首先提出了兩種擴散模型中抹除機制的概念模型：（i）降低生成目標概念的可能性，以及（ii）干擾模型的內部引導機制。為了徹底評估一個概念是否已真正從模型中抹除，我們引入了一套獨立的評估方法。我們的評估框架包括對抗性攻擊、新穎的探測技術以及對模型在抹除概念後產生的替代生成的分析。我們的結果揭示了最小化副作用和保持對抗性提示的穩健性之間的張力。總體而言，我們的工作強調了對擴散模型中抹除進行全面評估的重要性。", "applications": ["**內容安全與隱私保護：** 過濾掉AI生成圖像中涉及個人隱私或敏感資訊的部分，例如移除人臉上的特定特徵，防止AI生成深度偽造內容。", "**客製化與品牌安全：** 防止AI生成帶有負面或爭議性意涵的圖像，確保生成的內容符合品牌形象和價值觀，例如避免生成帶有政治立場或歧視性信息的圖像。", "**教育與創作自由：** 在教育領域，可過濾掉不適合成年人觀看的內容，讓孩子安全使用AI繪圖工具。同時，在創作領域，可以抹除不想要的元素，更精準地實現創作者的意圖。"], "pitch": "我們正在解決生成式AI一個核心但經常被忽視的問題：如何精確且可靠地控制AI的輸出，避免生成不需要甚至有害的內容。我們的研究揭示了現有概念抹除技術的局限性，並提供了一套更嚴謹的評估標準。這對於確保AI產品的安全性、合規性和道德性至關重要。想像一下，一個能完全控制AI生成內容的平台，可以安全地應用於廣告、教育、娛樂等各個領域，並且符合嚴格的監管要求。這不僅能降低企業的法律風險，更能提升品牌價值。我們的技術能為AI模型提供精確的控制力，確保其生成內容符合倫理規範和商業目標。我們正在尋找投資者，共同打造一個更安全、更可信賴的AI未來，並在這個快速增長的市場中佔據領先地位。", "audio": "audios/2505.17013v1.mp3", "timestamp": "2025-05-24T21:13:12.015788"}
{"query": "AI", "id": "2505.17021v1", "url": "http://arxiv.org/abs/2505.17021v1", "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "summary": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "authors": ["Sara Ghaboura", "Ketan More", "Wafa Alghallabi", "Omkar Thawakar", "Jorma Laaksonen", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "published_date": "2025-05-22", "title_zh": "ARB：一個全面的阿拉伯語多模態推理基準", "summary_zh": "大型多模態模型 (LMMs) 日益強大，但評估其推理過程的研究主要集中在英語。為了解決這個缺口，我們推出了阿拉伯語多模態推理基準 (ARB)，這是首個評估阿拉伯語文本和視覺模態逐步推理的基準。ARB 涵蓋 11 個領域，包含 1356 個多模態樣本和 5119 個人工策劃的推理步驟。我們評估了 12 個最先進的 LMMs，發現它們在連貫性、忠實性和文化基礎方面仍然面臨挑戰。ARB 提供了一個結構化的框架，用於診斷代表性不足語言的多模態推理，是邁向包容、透明和具有文化意識的 AI 系統的關鍵一步。", "applications": ["**中東地區智慧城市服務：** 基於阿拉伯語多模態推理的AI系統，能夠理解當地文化和習俗，提供更精準的導航、購物推薦和政府服務，例如識別阿拉伯語路牌和文件，並結合圖像資料提供導覽或資訊。", "**阿拉伯語教育輔助：** 用於開發更有效的阿拉伯語學習平台，通過視覺和文本資料，輔助學生理解複雜的概念和語法規則，並能評估學生的推理過程，提供個性化的學習建議。", "**阿拉伯藝術品與文物分析：** 結合文物圖片和相關阿拉伯語文獻，分析文物的歷史背景、文化意義和真偽，為博物館和藝術市場提供更可靠的資訊。例如，通過圖像識別和文字分析，判斷古籍的年代和作者。"], "pitch": "ARB 作為首個阿拉伯語多模態推理基準，解決了 LMM 在阿拉伯語領域的空白。這項技術的潛在商業價值巨大，尤其是在中東和北非地區，這些地區的阿拉伯語使用者眾多，但相關的 AI 技術發展相對滯後。基於 ARB 訓練的 LMM，能夠在中東智慧城市建設、文化遺產保護、阿拉伯語教育等多個領域提供更精準、更個性化的服務。對於投資者而言，這是一個進入快速增長的阿拉伯語 AI 市場的絕佳機會，可以搶佔先機，建立領導地位，並產生巨大的社會影響力，同時帶來豐厚的回報。", "audio": "audios/2505.17021v1.mp3", "timestamp": "2025-05-24T22:12:56.303538"}
{"query": "Foundation Model", "id": "2505.16982v1", "url": "http://arxiv.org/abs/2505.16982v1", "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "published_date": "2025-05-22", "title_zh": "超越相關性：邁向生物醫學領域的因果大型語言模型代理", "summary_zh": "大型語言模型在生物醫學領域展現潛力，但缺乏真正的因果理解，多仰賴相關性。本文提出因果大型語言模型代理的概念，整合多模態數據（文本、圖像、基因組等），並進行基於干預的推理，以推斷因果關係。實現此目標需克服多項挑戰：設計安全、可控的代理框架；開發嚴格的因果評估基準；整合異構數據源；以及將大型語言模型與結構化知識（知識圖譜）和正式因果推論工具協同結合。此類代理有潛力解鎖變革性機會，包括通過自動化假設生成和模擬來加速藥物發現，以及通過患者特異性因果模型實現個性化醫療。本研究旨在促進跨學科合作，將因果概念與基礎模型相結合，以開發可靠的人工智能夥伴，推動生物醫學進步。", "applications": ["**藥物研發加速器：** 模擬不同藥物對特定疾病的干預效果，大幅縮短臨床試驗週期並降低成本，例如預測某種基因編輯技術對於治療罕見疾病的效果。", "**個性化醫療助手：** 根據患者的基因、生活習慣、病史等數據，建立個體化的因果模型，預測不同治療方案的療效，從而為醫生提供更精準的治療建議，例如判斷某位高血壓患者對哪種降壓藥物的反應最佳。", "**公共衛生決策支持系統：** 分析大規模人群數據，找出環境因素、生活方式與疾病之間的因果關係，為公共衛生政策制定提供科學依據，例如評估某種飲食習慣對特定地區居民慢性病發病率的影響。"], "pitch": "我們正在開發基於因果理解的生物醫學大型語言模型，它不僅能分析數據，更能理解數據背後的因果關係，從而做出更準確的預測和決策。想像一下，一個能夠快速找到新藥靶點、為每個患者提供個性化治療方案、並能預測疫情發展趨勢的人工智能。我們的技術將顛覆生物醫學研究和臨床實踐，創造巨大的商業價值。我們尋求投資者共同打造這個劃時代的平台，將科學研究的成果更快、更有效地轉化為改善人類健康的工具，在萬億級的生物醫學市場中佔據領導地位。", "audio": "audios/2505.16982v1.mp3", "timestamp": "2025-05-24T22:13:20.791239"}
{"query": "Diffusion Model", "id": "2505.17013v1", "url": "http://arxiv.org/abs/2505.17013v1", "title": "When Are Concepts Erased From Diffusion Models?", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "published_date": "2025-05-22", "title_zh": "擴散模型中的概念何時被抹除？", "summary_zh": "概念抹除，即選擇性地阻止模型生成特定概念的能力，日益受到關注，並湧現出各種應對挑戰的方法。然而，這些方法抹除目標概念的徹底程度仍然不明確。我們首先提出了兩種用於擴散模型中抹除機制的概念模型：（i）降低生成目標概念的可能性，以及（ii）干擾模型的內部引導機制。為了徹底評估概念是否已真正從模型中抹除，我們引入了一套獨立的評估方法。我們的評估框架包括對抗性攻擊、新穎的探測技術，以及對模型在抹除概念後生成的替代方案的分析。我們的結果闡明了最小化副作用和保持對對抗性提示的魯棒性之間的緊張關係。總體而言，我們的工作強調了對擴散模型中抹除進行全面評估的重要性。", "applications": ["**內容審核：**自動生成內容的平台可以利用概念抹除技術，防止模型生成仇恨言論、暴力內容或錯誤信息，確保平台內容的合規性和安全性。", "**保護個人隱私：**在處理包含個人信息的圖像或數據時，可以抹除敏感概念（例如人臉、地址），以保護個人隱私，同時仍能利用其他有用的信息。", "**藝術創作：**藝術家可以利用概念抹除技術來消除創作過程中的特定元素或主題，以探索新的藝術方向，並創造出更具創意和獨特性的作品。"], "pitch": "我們開發的技術能精準控制AI生成模型，徹底抹除特定概念，避免不良內容產生、保護隱私。這項技術不僅適用於內容平台的風險控管，降低法律風險，更能在資料處理、藝術創作等領域創造全新價值。想像一下，一個能自我審查的AI內容生成引擎，或者是一個能精準移除敏感個資的數據分析工具，市場潛力巨大。我們提供更安全、更可控的AI解決方案，讓企業在享受AI紅利的同時，也能有效避免潛在風險。", "audio": "audios/2505.17013v1.mp3", "timestamp": "2025-05-24T22:13:47.216127"}
{"query": "AI", "id": "2505.16619v1", "url": "http://arxiv.org/abs/2505.16619v1", "title": "Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences", "summary": "Artificial intelligence (AI) has recently seen transformative breakthroughs\nin the life sciences, expanding possibilities for researchers to interpret\nbiological information at an unprecedented capacity, with novel applications\nand advances being made almost daily. In order to maximise return on the\ngrowing investments in AI-based life science research and accelerate this\nprogress, it has become urgent to address the exacerbation of long-standing\nresearch challenges arising from the rapid adoption of AI methods. We review\nthe increased erosion of trust in AI research outputs, driven by the issues of\npoor reusability and reproducibility, and highlight their consequent impact on\nenvironmental sustainability. Furthermore, we discuss the fragmented components\nof the AI ecosystem and lack of guiding pathways to best support Open and\nSustainable AI (OSAI) model development. In response, this perspective\nintroduces a practical set of OSAI recommendations directly mapped to over 300\ncomponents of the AI ecosystem. Our work connects researchers with relevant AI\nresources, facilitating the implementation of sustainable, reusable and\ntransparent AI. Built upon life science community consensus and aligned to\nexisting efforts, the outputs of this perspective are designed to aid the\nfuture development of policy and structured pathways for guiding AI\nimplementation.", "authors": ["Gavin Farrell", "Eleni Adamidi", "Rafael Andrade Buono", "Mihail Anton", "Omar Abdelghani Attafi", "Salvador Capella Gutierrez", "Emidio Capriotti", "Leyla Jael Castro", "Davide Cirillo", "Lisa Crossman", "Christophe Dessimoz", "Alexandros Dimopoulos", "Raul Fernandez-Diaz", "Styliani-Christina Fragkouli", "Carole Goble", "Wei Gu", "John M. Hancock", "Alireza Khanteymoori", "Tom Lenaerts", "Fabio G. Liberante", "Peter Maccallum", "Alexander Miguel Monzon", "Magnus Palmblad", "Lucy Poveda", "Ovidiu Radulescu", "Denis C. Shields", "Shoaib Sufi", "Thanasis Vergoulis", "Fotis Psomopoulos", "Silvio C. E. Tosatto"], "published_date": "2025-05-22", "title_zh": "開放且永續的人工智慧：生命科學領域的挑戰、機會與未來之路", "summary_zh": "這篇論文探討了人工智慧在生命科學領域快速發展所帶來的挑戰，特別是可重用性、可再現性不足導致對AI研究成果信任度下降，以及對環境永續性的影響。論文強調AI生態系統的碎片化，並提出一套實際的開放且永續AI(OSAI)建議，將研究人員與相關的AI資源連接起來，以促進永續、可重用且透明的AI實施。目的是協助制定政策和結構化路徑，指導AI在生命科學領域的應用。", "applications": ["**加速新藥開發：** 利用OSAI原則，確保AI模型訓練數據的透明度和可追溯性，以及模型的可重用性，加速藥物靶點的發現和先導化合物的篩選，大幅縮短新藥研發週期。", "**精準醫療診斷：** 透過開放的AI模型和數據，可以建立更可靠的疾病診斷模型，幫助醫生更準確地診斷疾病，並制定個性化的治療方案，提高治療效果。", "**環境監測與保護：** 利用AI分析環境數據，例如空氣品質、水質等，早期發現環境污染問題，並預測未來的環境變化趨勢。基於OSAI原則，確保數據的開放性和模型的透明度，讓更多人參與到環境保護的行動中來。"], "pitch": "各位投資人，我們正處於AI技術與生命科學交匯的黃金時代。這篇論文揭示了行業痛點：AI在生命科學的應用雖潜力無限，但可重現性差、資源分散，阻礙了其發展。我們的機會在於，將論文提出的OSAI原則商業化，打造一個開放、可信賴、可持續的AI平台，專注於生命科學領域。想象一下，一個能大幅加速新藥研發、提供精準診斷方案、提升環境監測效率的平台！我們將通過提供標準化的數據集、開源模型庫、以及專業的AI諮詢服務，吸引藥企、醫院、科研機構等客戶。我們的商業模式包括訂閱服務、模型定製和諮詢費用。憑藉對行業痛點的深刻理解和獨特的OSAI解決方案，我們有信心在這個百億美元級的市場中佔據一席之地，為投資人帶來豐厚的回報。這不僅是一項商業投資，更是對未來生命科學發展的投資，讓我們共同見證AI如何改變世界！", "audio": "audios/2505.16619v1.mp3", "timestamp": "2025-05-25T00:56:40.527521"}
{"query": "Foundation Model", "id": "2505.14975v1", "url": "http://arxiv.org/abs/2505.14975v1", "title": "Flattening Hierarchies with Policy Bootstrapping", "summary": "Offline goal-conditioned reinforcement learning (GCRL) is a promising\napproach for pretraining generalist policies on large datasets of reward-free\ntrajectories, akin to the self-supervised objectives used to train foundation\nmodels for computer vision and natural language processing. However, scaling\nGCRL to longer horizons remains challenging due to the combination of sparse\nrewards and discounting, which obscures the comparative advantages of primitive\nactions with respect to distant goals. Hierarchical RL methods achieve strong\nempirical results on long-horizon goal-reaching tasks, but their reliance on\nmodular, timescale-specific policies and subgoal generation introduces\nsignificant additional complexity and hinders scaling to high-dimensional goal\nspaces. In this work, we introduce an algorithm to train a flat\n(non-hierarchical) goal-conditioned policy by bootstrapping on\nsubgoal-conditioned policies with advantage-weighted importance sampling. Our\napproach eliminates the need for a generative model over the (sub)goal space,\nwhich we find is key for scaling to high-dimensional control in large state\nspaces. We further show that existing hierarchical and bootstrapping-based\napproaches correspond to specific design choices within our derivation. Across\na comprehensive suite of state- and pixel-based locomotion and manipulation\nbenchmarks, our method matches or surpasses state-of-the-art offline GCRL\nalgorithms and scales to complex, long-horizon tasks where prior approaches\nfail.", "authors": ["John L. Zhou", "Jonathan C. Kao"], "published_date": "2025-05-20", "title_zh": "利用策略引導扁平化層級結構", "summary_zh": "離線目標條件強化學習 (GCRL) 是一種有前景的方法，可用於在大型無獎勵軌跡數據集上預訓練通用策略，類似於用於訓練電腦視覺和自然語言處理基礎模型的自我監督目標。然而，由於稀疏獎勵和折扣的結合，使得遠距離目標下原始動作的相對優勢不明顯，因此將 GCRL 擴展到更長的時間範圍仍然具有挑戰性。分層強化學習方法在長時距目標達成任務上取得了強大的經驗成果，但它們對模組化、特定時間尺度的策略和子目標生成模型的依賴引入了顯著的額外複雜性，並阻礙了擴展到高維目標空間。在這項工作中，我們介紹了一種算法，通過對子目標條件策略進行優勢加權重要性採樣引導，來訓練扁平（非分層）目標條件策略。我們的方法消除了對目標空間（子目標）生成模型的需求，我們發現這對於在高維狀態空間中擴展到高維控制至關重要。我們進一步表明，現有的分層和基於引導的方法對應於我們推導中的特定設計選擇。在全面的基於狀態和基於像素的運動和操縱基準測試中，我們的方法與最先進的離線 GCRL 算法相匹配或超越，並且可以擴展到以前的方法失敗的複雜長時距任務。", "applications": ["**智能家居控制:** 讓機器人學習複雜的家居任務，例如整理凌亂的房間或準備包含多個步驟的食物，而無需預先定義所有子任務。", "**自動駕駛規劃:** 訓練自動駕駛系統處理複雜的駕駛場景，例如在高流量環境中進行多車道變換和安全超車，並在沒有明確中間目標的情況下安全抵達目的地。", "**機器人手術輔助:** 指導機器人完成精確的手術操作，例如在狹窄空間中定位和操作微型器械，而無需人工定義每個步驟的精確位置和角度。"], "pitch": "我們開發了一種突破性的離線強化學習技術，能夠訓練機器人或其他智能體在複雜、長時距任務中表現出色，且無需昂貴的人工標注或複雜的層級結構設計。我們的算法通過『扁平化』學習過程，極大地簡化了訓練，並能有效利用大量的無標註數據。這項技術的潛在商業價值巨大，能夠顛覆諸如智能家居、自動駕駛、機器人自動化等領域。想像一下，無需專業編程人員，機器人就能通過學習大量的數據輕鬆掌握複雜的任務。我們相信，我們的技術將成為下一代 AI 智能體的核心引擎，為各行業帶來革命性的變革。我們的團隊正在尋求種子輪融資，以加速算法的完善和商業化落地，把握這一巨大的市場機遇。", "audio": "audios/2505.14975v1.mp3", "timestamp": "2025-05-25T00:57:14.345584"}
{"query": "Diffusion Model", "id": "2505.16174v1", "url": "http://arxiv.org/abs/2505.16174v1", "title": "Erased or Dormant? Rethinking Concept Erasure Through Reversibility", "summary": "To what extent does concept erasure eliminate generative capacity in\ndiffusion models? While prior evaluations have primarily focused on measuring\nconcept suppression under specific textual prompts, we explore a complementary\nand fundamental question: do current concept erasure techniques genuinely\nremove the ability to generate targeted concepts, or do they merely achieve\nsuperficial, prompt-specific suppression? We systematically evaluate the\nrobustness and reversibility of two representative concept erasure methods,\nUnified Concept Editing and Erased Stable Diffusion, by probing their ability\nto eliminate targeted generative behaviors in text-to-image models. These\nmethods attempt to suppress undesired semantic concepts by modifying internal\nmodel parameters, either through targeted attention edits or model-level\nfine-tuning strategies. To rigorously assess whether these techniques truly\nerase generative capacity, we propose an instance-level evaluation strategy\nthat employs lightweight fine-tuning to explicitly test the reactivation\npotential of erased concepts. Through quantitative metrics and qualitative\nanalyses, we show that erased concepts often reemerge with substantial visual\nfidelity after minimal adaptation, indicating that current methods suppress\nlatent generative representations without fully eliminating them. Our findings\nreveal critical limitations in existing concept erasure approaches and\nhighlight the need for deeper, representation-level interventions and more\nrigorous evaluation standards to ensure genuine, irreversible removal of\nconcepts from generative models.", "authors": ["Ping Liu", "Chi Zhang"], "published_date": "2025-05-22", "title_zh": "擦除還是休眠？透過可逆性重新思考概念擦除", "summary_zh": "現有的概念擦除技術，例如Unified Concept Editing和Erased Stable Diffusion，聲稱可以移除生成模型中特定概念的生成能力。但這篇論文質疑這些技術是否真的完全移除了概念，還是只是做到了表面上的壓制。研究發現，這些方法雖然可以暫時阻止模型生成特定概念，但透過輕微的微調，這些概念很容易重新浮現，顯示這些技術只是壓制了潛在的生成表示，並沒有徹底消除它們。因此，論文強調，現有的概念擦除方法存在關鍵局限性，需要更深入的表示層級干預和更嚴格的評估標準，以確保真正且不可逆地從生成模型中移除概念。", "applications": ["**內容審核與安全：** 針對可能產生有害內容的特定概念（例如暴力、仇恨言論）進行更有效的擦除，確保模型不會生成相關內容，降低平台風險。", "**客製化模型與風格轉移：**  更精確地擦除原始模型的某些風格或特定對象，讓使用者能更自由地控制生成結果，創造出更個性化的內容，例如移除特定畫家的風格。", "**智慧財產權保護：**  移除模型訓練資料中的敏感或受版權保護的內容，防止模型生成侵權內容，保護創作者的權益。"], "pitch": "想像一下，你擁有一項技術，能讓AI徹底忘記某個概念。這不僅僅是表面功夫，而是真正從模型的核心中移除。這篇論文揭示了現有技術的局限性，但也指出了未來發展的方向。我們的願景是開發一種更強大的概念擦除技術，其商業價值巨大：\n\n*   **提升AI平台的安全性與合規性：** 降低生成有害或侵權內容的風險，避免法律訴訟與品牌聲譽受損。\n*   **賦予使用者更大的控制權：** 開放更多客製化選項，滿足不同使用者的需求，提高產品吸引力。\n*   **開創新的應用場景：** 在內容創作、智慧財產權保護等領域，提供獨特的解決方案，建立市場競爭優勢。\n\n我們正在尋求投資，以加速研發更有效的概念擦除技術，並將其商業化。這不僅是一項技術投資，更是一項對未來AI發展方向的投資，確保AI的發展符合倫理、安全和法律規範，並為社會帶來更大的價值。", "audio": "audios/2505.16174v1.mp3", "timestamp": "2025-05-25T00:57:43.910291"}
{"query": "AI", "id": "2505.16619v1", "url": "http://arxiv.org/abs/2505.16619v1", "title": "Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences", "summary": "Artificial intelligence (AI) has recently seen transformative breakthroughs\nin the life sciences, expanding possibilities for researchers to interpret\nbiological information at an unprecedented capacity, with novel applications\nand advances being made almost daily. In order to maximise return on the\ngrowing investments in AI-based life science research and accelerate this\nprogress, it has become urgent to address the exacerbation of long-standing\nresearch challenges arising from the rapid adoption of AI methods. We review\nthe increased erosion of trust in AI research outputs, driven by the issues of\npoor reusability and reproducibility, and highlight their consequent impact on\nenvironmental sustainability. Furthermore, we discuss the fragmented components\nof the AI ecosystem and lack of guiding pathways to best support Open and\nSustainable AI (OSAI) model development. In response, this perspective\nintroduces a practical set of OSAI recommendations directly mapped to over 300\ncomponents of the AI ecosystem. Our work connects researchers with relevant AI\nresources, facilitating the implementation of sustainable, reusable and\ntransparent AI. Built upon life science community consensus and aligned to\nexisting efforts, the outputs of this perspective are designed to aid the\nfuture development of policy and structured pathways for guiding AI\nimplementation.", "authors": ["Gavin Farrell", "Eleni Adamidi", "Rafael Andrade Buono", "Mihail Anton", "Omar Abdelghani Attafi", "Salvador Capella Gutierrez", "Emidio Capriotti", "Leyla Jael Castro", "Davide Cirillo", "Lisa Crossman", "Christophe Dessimoz", "Alexandros Dimopoulos", "Raul Fernandez-Diaz", "Styliani-Christina Fragkouli", "Carole Goble", "Wei Gu", "John M. Hancock", "Alireza Khanteymoori", "Tom Lenaerts", "Fabio G. Liberante", "Peter Maccallum", "Alexander Miguel Monzon", "Magnus Palmblad", "Lucy Poveda", "Ovidiu Radulescu", "Denis C. Shields", "Shoaib Sufi", "Thanasis Vergoulis", "Fotis Psomopoulos", "Silvio C. E. Tosatto"], "published_date": "2025-05-22", "title_zh": "開放且永續的人工智慧：生命科學領域的挑戰、機遇與未來發展方向", "summary_zh": "人工智慧正在革新生命科學，但快速發展也帶來了可重複性、可再用性以及環境永續性等問題，導致信任度下降。本論文探討了AI生態系統的碎片化，並提出一套實用的開放且永續AI（OSAI）建議，涵蓋300多個AI生態系統組成部分，旨在促進生命科學研究的可持續、可重複和透明的人工智慧應用。", "applications": ["**加速新藥開發：** 透過可重複且透明的AI模型，藥廠能更快速地驗證藥物療效，降低研發成本和時間。", "**精準醫療診斷：** 基於開放數據和永續AI模型，醫生能更準確地診斷疾病，提供個人化的治療方案，提升醫療品質。", "**環境監測與生物多樣性保護：** 利用AI分析環境數據，監測污染狀況和生物多樣性變化，協助制定有效的保護策略，維護生態平衡。"], "pitch": "生命科學AI正處於爆發期，但缺乏標準化和永續性將阻礙其發展。我們的團隊提供一套完整的OSAI解決方案，協助生命科學公司和研究機構構建可信賴、可重複且具備環境意識的AI模型。透過提高研發效率、降低風險和實現數據共享，我們將加速生命科學領域的創新，創造巨大的商業價值。想像一下，一家藥廠利用我們的OSAI框架，在短短幾個月內成功開發出一種治療阿茲海默症的新藥，這將帶來數十億美元的收入和無數患者的福音。我們正在構建生命科學AI的未來，歡迎加入我們，共同引領這場變革！", "audio": "audios/2505.16619v1.mp3", "timestamp": "2025-05-25T01:10:59.166131"}
{"query": "Foundation Model", "id": "2505.14975v1", "url": "http://arxiv.org/abs/2505.14975v1", "title": "Flattening Hierarchies with Policy Bootstrapping", "summary": "Offline goal-conditioned reinforcement learning (GCRL) is a promising\napproach for pretraining generalist policies on large datasets of reward-free\ntrajectories, akin to the self-supervised objectives used to train foundation\nmodels for computer vision and natural language processing. However, scaling\nGCRL to longer horizons remains challenging due to the combination of sparse\nrewards and discounting, which obscures the comparative advantages of primitive\nactions with respect to distant goals. Hierarchical RL methods achieve strong\nempirical results on long-horizon goal-reaching tasks, but their reliance on\nmodular, timescale-specific policies and subgoal generation introduces\nsignificant additional complexity and hinders scaling to high-dimensional goal\nspaces. In this work, we introduce an algorithm to train a flat\n(non-hierarchical) goal-conditioned policy by bootstrapping on\nsubgoal-conditioned policies with advantage-weighted importance sampling. Our\napproach eliminates the need for a generative model over the (sub)goal space,\nwhich we find is key for scaling to high-dimensional control in large state\nspaces. We further show that existing hierarchical and bootstrapping-based\napproaches correspond to specific design choices within our derivation. Across\na comprehensive suite of state- and pixel-based locomotion and manipulation\nbenchmarks, our method matches or surpasses state-of-the-art offline GCRL\nalgorithms and scales to complex, long-horizon tasks where prior approaches\nfail.", "authors": ["John L. Zhou", "Jonathan C. Kao"], "published_date": "2025-05-20", "title_zh": "利用策略引導展平層級結構", "summary_zh": "離線目標條件強化學習 (GCRL) 是一種很有前景的方法，可以在大量的無獎勵軌跡數據集上預訓練通用策略，類似於用於訓練計算機視覺和自然語言處理基礎模型的自監督目標。然而，由於稀疏獎勵和折扣的結合，使得原始動作相對於遠期目標的比較優勢變得模糊，將 GCRL 擴展到更長的時間範圍仍然具有挑戰性。層級強化學習方法在長時期目標達成任務上取得了強大的經驗結果，但它們對模塊化、特定時間尺度的策略和子目標生成的依賴引入了顯著的額外複雜性，並阻礙了擴展到高維目標空間。在這項工作中，我們引入了一種算法，通過對具有優勢加權重要性抽樣的子目標條件策略進行引導，來訓練一個扁平（非層級）的目標條件策略。我們的方法消除了對 (子) 目標空間的生成模型的需要，我們發現這是在大型狀態空間中擴展到高維控制的關鍵。我們進一步表明，現有的層級和基於引導的方法對應於我們推導中的特定設計選擇。在全面的基於狀態和基於像素的運動和操縱基準測試中，我們的算法與最先進的離線 GCRL 算法相匹配或超過，並可擴展到先前方法失敗的複雜的長時期任務。", "applications": ["**機器人流程自動化：** 讓機器人能夠學習複雜的組裝或維修任務，即使在訓練數據有限且沒有明確獎勵的情況下，例如自動組裝電子產品或修理汽車引擎。", "**虛擬人物控制：** 在遊戲或虛擬現實環境中，創造能夠自主完成複雜任務的虛擬人物，例如在開放世界遊戲中導航、社交互動或執行複雜的動作。", "**個性化醫療：** 根據患者的歷史數據和目標（例如，控制血糖、減肥），制定個性化的治療方案。模型可以學習在沒有明確獎勵的情況下，哪些干預措施對患者有效。"], "pitch": "這項研究成果解決了離線強化學習在長程目標達成任務中的關鍵瓶頸。通過展平層級結構，消除了對複雜子目標生成模型的依賴，顯著提高了算法的可擴展性和效率。這使得我們能夠在計算機視覺、機器人流程自動化以及個性化醫療等領域開發更強大、更通用的 AI 解決方案。其潛在的商業價值在於大幅降低開發成本、提高自動化程度、並實現前所未有的個性化服務，為相關產業帶來顛覆性變革。", "audio": "audios/2505.14975v1.mp3", "timestamp": "2025-05-25T01:11:26.182020"}
{"query": "Diffusion Model", "id": "2505.16174v1", "url": "http://arxiv.org/abs/2505.16174v1", "title": "Erased or Dormant? Rethinking Concept Erasure Through Reversibility", "summary": "To what extent does concept erasure eliminate generative capacity in\ndiffusion models? While prior evaluations have primarily focused on measuring\nconcept suppression under specific textual prompts, we explore a complementary\nand fundamental question: do current concept erasure techniques genuinely\nremove the ability to generate targeted concepts, or do they merely achieve\nsuperficial, prompt-specific suppression? We systematically evaluate the\nrobustness and reversibility of two representative concept erasure methods,\nUnified Concept Editing and Erased Stable Diffusion, by probing their ability\nto eliminate targeted generative behaviors in text-to-image models. These\nmethods attempt to suppress undesired semantic concepts by modifying internal\nmodel parameters, either through targeted attention edits or model-level\nfine-tuning strategies. To rigorously assess whether these techniques truly\nerase generative capacity, we propose an instance-level evaluation strategy\nthat employs lightweight fine-tuning to explicitly test the reactivation\npotential of erased concepts. Through quantitative metrics and qualitative\nanalyses, we show that erased concepts often reemerge with substantial visual\nfidelity after minimal adaptation, indicating that current methods suppress\nlatent generative representations without fully eliminating them. Our findings\nreveal critical limitations in existing concept erasure approaches and\nhighlight the need for deeper, representation-level interventions and more\nrigorous evaluation standards to ensure genuine, irreversible removal of\nconcepts from generative models.", "authors": ["Ping Liu", "Chi Zhang"], "published_date": "2025-05-22", "title_zh": "擦除還是休眠？透過可逆性重新思考概念擦除", "summary_zh": "這篇論文探討了概念擦除技術在扩散模型中消除生成能力的效果。現有的技術主要集中在特定文字提示下的概念抑制，但本文深入研究這些技術是否真正移除了生成目標概念的能力，還是僅僅實現了表面上的、提示特定的抑制。研究人員通過測試兩種代表性的概念擦除方法，發現這些方法雖然能抑制潛在的生成表示，但並不能完全消除它們。經過輕微的調整，被“擦除”的概念通常會重新出現，表明需要更深層次的干預和更嚴格的評估標準，才能確保從生成模型中真正且不可逆地移除概念。", "applications": ["**內容審核與過濾：** 用於過濾生成模型產生的不適當內容，例如仇恨言論、暴力圖像或色情內容。若僅為表面抑制，則模型可能在稍作調整後再度生成違規內容，突顯了不可逆擦除的重要性。", "**個性化教育：** 針對特定學習者調整生成式學習工具，避免生成可能引起反感或不適的圖像或文本。例如，避免生成涉及學生創傷經歷的內容。", "**品牌保護：** 確保品牌生成內容時，不會產生與競爭對手相關或損害品牌形象的內容。確保擦除競品概念的不可逆性，避免在不知情下生成競品相關內容。"], "pitch": "我們發現現有的AI概念擦除技術存在重大缺陷，無法真正且不可逆地移除生成模型中的有害或不適當概念。這為我們提供了一個巨大的商業機會，開發更有效的概念擦除解決方案，確保生成式AI的安全性、合規性和商業價值。我們的技術將賦能企業安全地使用生成式AI，避免潛在的法律和聲譽風險，並開創個性化內容和安全AI的新市場。這個市場規模龐大，隨著生成式AI的普及，對於可信賴的內容過濾和控制解決方案的需求將持續增長。我們的團隊擁有領先的研究能力和技術實力，能夠率先解決這個關鍵挑戰，成為行業領導者。", "audio": "audios/2505.16174v1.mp3", "timestamp": "2025-05-25T01:11:50.317313"}
{"query": "AI", "id": "2505.16619v1", "url": "http://arxiv.org/abs/2505.16619v1", "title": "Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences", "summary": "Artificial intelligence (AI) has recently seen transformative breakthroughs\nin the life sciences, expanding possibilities for researchers to interpret\nbiological information at an unprecedented capacity, with novel applications\nand advances being made almost daily. In order to maximise return on the\ngrowing investments in AI-based life science research and accelerate this\nprogress, it has become urgent to address the exacerbation of long-standing\nresearch challenges arising from the rapid adoption of AI methods. We review\nthe increased erosion of trust in AI research outputs, driven by the issues of\npoor reusability and reproducibility, and highlight their consequent impact on\nenvironmental sustainability. Furthermore, we discuss the fragmented components\nof the AI ecosystem and lack of guiding pathways to best support Open and\nSustainable AI (OSAI) model development. In response, this perspective\nintroduces a practical set of OSAI recommendations directly mapped to over 300\ncomponents of the AI ecosystem. Our work connects researchers with relevant AI\nresources, facilitating the implementation of sustainable, reusable and\ntransparent AI. Built upon life science community consensus and aligned to\nexisting efforts, the outputs of this perspective are designed to aid the\nfuture development of policy and structured pathways for guiding AI\nimplementation.", "authors": ["Gavin Farrell", "Eleni Adamidi", "Rafael Andrade Buono", "Mihail Anton", "Omar Abdelghani Attafi", "Salvador Capella Gutierrez", "Emidio Capriotti", "Leyla Jael Castro", "Davide Cirillo", "Lisa Crossman", "Christophe Dessimoz", "Alexandros Dimopoulos", "Raul Fernandez-Diaz", "Styliani-Christina Fragkouli", "Carole Goble", "Wei Gu", "John M. Hancock", "Alireza Khanteymoori", "Tom Lenaerts", "Fabio G. Liberante", "Peter Maccallum", "Alexander Miguel Monzon", "Magnus Palmblad", "Lucy Poveda", "Ovidiu Radulescu", "Denis C. Shields", "Shoaib Sufi", "Thanasis Vergoulis", "Fotis Psomopoulos", "Silvio C. E. Tosatto"], "published_date": "2025-05-22", "title_zh": "開放且永續的人工智慧：生命科學領域的挑戰、機會與未來發展之路", "summary_zh": "人工智慧在生命科學領域迎來突破性進展，為研究人員以前所未有的能力解讀生物資訊提供了可能。然而，AI快速普及也加劇了長期存在的科研挑戰，如AI研究成果的可重複使用性與可再現性不佳，進而侵蝕信任並影響環境永續性。本文探討了AI生態系統的碎片化問題，並提出一套基於生命科學社群共識、與現有努力保持一致的「開放且永續AI (OSAI)」實用建議，旨在連接研究人員與相關AI資源，促進可持續、可重複使用和透明的AI實施，並為未來政策制定和AI實施的結構化路徑提供指導。", "applications": ["**加速新藥開發：** 透過可重複使用的AI模型，更快速篩選潛在藥物靶點，降低藥物開發成本。", "**精準醫療診斷：** 開放且透明的AI診斷模型，能夠提高診斷準確性，減少誤診，為患者提供個性化治療方案。", "**永續農業優化：** 利用AI分析土壤、氣候等數據，開發可持續的農業模型，提高作物產量，減少對環境的負擔。"], "pitch": "生命科學領域正在經歷AI驅動的革命，但重複性差、永續性不足的問題阻礙了發展。我們的OSAI解決方案提供了一個標準化的框架和資源庫，確保AI模型的可重複使用、可持續發展。這不僅能加速新藥開發、精準醫療等領域的創新，更能為生命科學研究帶來更高的投資回報率。想像一下，一個開放的AI平台，讓全球的研究人員協同合作，共同解決人類面臨的健康挑戰。這不僅是一個技術投資，更是一個對人類福祉的投資。 我們正在打造一個開放、透明、可信賴的AI生態系統，引領生命科學的未來。", "audio": "audios/2505.16619v1.mp3", "timestamp": "2025-05-25T01:24:56.495559"}
{"query": "Foundation Model", "id": "2505.14975v1", "url": "http://arxiv.org/abs/2505.14975v1", "title": "Flattening Hierarchies with Policy Bootstrapping", "summary": "Offline goal-conditioned reinforcement learning (GCRL) is a promising\napproach for pretraining generalist policies on large datasets of reward-free\ntrajectories, akin to the self-supervised objectives used to train foundation\nmodels for computer vision and natural language processing. However, scaling\nGCRL to longer horizons remains challenging due to the combination of sparse\nrewards and discounting, which obscures the comparative advantages of primitive\nactions with respect to distant goals. Hierarchical RL methods achieve strong\nempirical results on long-horizon goal-reaching tasks, but their reliance on\nmodular, timescale-specific policies and subgoal generation introduces\nsignificant additional complexity and hinders scaling to high-dimensional goal\nspaces. In this work, we introduce an algorithm to train a flat\n(non-hierarchical) goal-conditioned policy by bootstrapping on\nsubgoal-conditioned policies with advantage-weighted importance sampling. Our\napproach eliminates the need for a generative model over the (sub)goal space,\nwhich we find is key for scaling to high-dimensional control in large state\nspaces. We further show that existing hierarchical and bootstrapping-based\napproaches correspond to specific design choices within our derivation. Across\na comprehensive suite of state- and pixel-based locomotion and manipulation\nbenchmarks, our method matches or surpasses state-of-the-art offline GCRL\nalgorithms and scales to complex, long-horizon tasks where prior approaches\nfail.", "authors": ["John L. Zhou", "Jonathan C. Kao"], "published_date": "2025-05-20", "title_zh": "利用策略引導展平層級結構", "summary_zh": "離線目標條件強化學習 (GCRL) 是一種很有潛力的技術，可以在大型無獎勵軌跡數據集上預訓練通用策略，就像用於訓練電腦視覺和自然語言處理基礎模型的自我監督目標一樣。 然而，由於稀疏獎勵和折扣的結合，使得原始動作相對於遠期目標的比較優勢變得模糊，因此將 GCRL 擴展到更長的時間範圍仍然具有挑戰性。層級強化學習方法在長時程目標達成任務上取得了強大的經驗結果，但它們對模組化、特定時間尺度的策略和子目標生成的依賴引入了顯著的額外複雜性，並阻礙了擴展到高維目標空間。 在這項工作中，我們引入了一種算法，通過使用優勢加權重要性採樣引導子目標條件策略，來訓練一個扁平的（非層級的）目標條件策略。 我們的算法消除了對（子）目標空間的生成模型的需求，我們發現這對於在高維狀態空間中擴展到高維控制至關重要。 我們進一步表明，現有的基於層級和引導的方法對應於我們推導中的特定設計選擇。 在一套全面的基於狀態和像素的運動和操作基準測試中，我們的方法與最先進的離線 GCRL 算法相匹配或超過了它們，並且可以擴展到以前的方法失敗的複雜的長時程任務。", "applications": ["**機器人家庭助理：**訓練機器人完成複雜的家務，例如從冰箱取出飲料並送到指定地點。透過學習分解任務，機器人可以更有效率地完成長序列動作。", "**自動駕駛：**在模擬環境中訓練自動駕駛汽車，使其能夠安全地完成長途駕駛任務，例如從一個城市導航到另一個城市，而無需人工標記大量獎勵數據。", "**遊戲AI：**開發更聰明的遊戲AI，讓AI角色能夠制定長期策略，例如在即時戰略遊戲中有效地管理資源和執行複雜的攻擊計畫。"], "pitch": "這項技術突破能夠讓機器學習模型，特別是機器人，以更有效率的方式學習執行複雜、長期的任務。傳統上，這需要複雜的層級結構，但我們的'展平'方法不僅簡化了流程，還提升了效能，尤其是在高維環境中。想像一下，不再需要大量的人工數據，AI就能夠自主學習執行多步驟的任務，例如組裝產品、駕駛車輛，甚至是照護病人。其商業價值在於降低了開發成本，提高了自動化的可能性，並開創了全新的應用場景。我們的技術能夠讓機器人更智能、更自主，從而改變製造業、物流業、醫療保健等產業。我們需要資金來進一步優化算法，並將其應用於不同的領域，以證明其廣泛的適用性和商業可行性。我們相信，我們的技術將成為下一代自主系統的基礎。", "audio": "audios/2505.14975v1.mp3", "timestamp": "2025-05-25T01:25:19.548329"}
{"query": "Diffusion Model", "id": "2505.16174v1", "url": "http://arxiv.org/abs/2505.16174v1", "title": "Erased or Dormant? Rethinking Concept Erasure Through Reversibility", "summary": "To what extent does concept erasure eliminate generative capacity in\ndiffusion models? While prior evaluations have primarily focused on measuring\nconcept suppression under specific textual prompts, we explore a complementary\nand fundamental question: do current concept erasure techniques genuinely\nremove the ability to generate targeted concepts, or do they merely achieve\nsuperficial, prompt-specific suppression? We systematically evaluate the\nrobustness and reversibility of two representative concept erasure methods,\nUnified Concept Editing and Erased Stable Diffusion, by probing their ability\nto eliminate targeted generative behaviors in text-to-image models. These\nmethods attempt to suppress undesired semantic concepts by modifying internal\nmodel parameters, either through targeted attention edits or model-level\nfine-tuning strategies. To rigorously assess whether these techniques truly\nerase generative capacity, we propose an instance-level evaluation strategy\nthat employs lightweight fine-tuning to explicitly test the reactivation\npotential of erased concepts. Through quantitative metrics and qualitative\nanalyses, we show that erased concepts often reemerge with substantial visual\nfidelity after minimal adaptation, indicating that current methods suppress\nlatent generative representations without fully eliminating them. Our findings\nreveal critical limitations in existing concept erasure approaches and\nhighlight the need for deeper, representation-level interventions and more\nrigorous evaluation standards to ensure genuine, irreversible removal of\nconcepts from generative models.", "authors": ["Ping Liu", "Chi Zhang"], "published_date": "2025-05-22", "title_zh": "抹除還是休眠？透過可逆性重新思考概念抹除", "summary_zh": "這篇論文探討了現有的概念抹除技術，像是用來過濾掉擴散模型中不想要的內容，究竟是真正移除了模型生成特定概念的能力，還是只是表面上的抑制。研究發現，現有的抹除方法其實只是讓這些概念暫時休眠，透過輕微的調整就能讓它們重新出現。這代表現在的技術只能抑制潛在的生成表現，而無法徹底根除這些概念。研究強調需要更深入的干預措施和更嚴格的評估標準，才能真正且不可逆地從生成模型中移除概念。", "applications": ["**內容安全過濾器強化：** 開發更可靠的內容過濾器，防止生成帶有偏見、歧視或有害內容的圖像，即使模型經過惡意調整也難以繞過。", "**IP保護與藝術風格控制：** 藝術家或品牌可以保護自己的風格，防止未經授權的模仿，並更精準地控制AI生成的圖像風格，確保不會意外出現不想要的風格元素。", "**模型客製化與微調：** 用戶可以更精確地移除預訓練模型中不必要的概念，為特定應用客製化模型，例如醫療影像分析中移除會分散注意力的雜訊，提升診斷準確性。"], "pitch": "現有的AI圖像生成模型存在潛在的風險，可能會生成不當或侵權內容。我們基於這項研究，開發了一種更強大的概念抹除技術，能真正且不可逆地從模型中移除特定概念，而非僅僅是表面抑制。這項技術將成為AI圖像生成平台的基礎安全層，降低法律風險、保護IP，並賦予用戶更精確的控制權。我們的商業模式包括技術授權、開發工具套件，以及為企業提供客製化的抹除服務。目標客戶包含但不限於：AI圖像生成平台、內容審核服務供應商、以及擁有大量IP的企業。這項技術解決了目前市場上缺乏有效內容安全方案的痛點，具備巨大的商業潛力，預計將在AI圖像生成市場中佔據領先地位。", "audio": "audios/2505.16174v1.mp3", "timestamp": "2025-05-25T01:25:33.984659"}
{"query": "AI", "id": "2505.16619v1", "url": "http://arxiv.org/abs/2505.16619v1", "title": "Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences", "summary": "Artificial intelligence (AI) has recently seen transformative breakthroughs\nin the life sciences, expanding possibilities for researchers to interpret\nbiological information at an unprecedented capacity, with novel applications\nand advances being made almost daily. In order to maximise return on the\ngrowing investments in AI-based life science research and accelerate this\nprogress, it has become urgent to address the exacerbation of long-standing\nresearch challenges arising from the rapid adoption of AI methods. We review\nthe increased erosion of trust in AI research outputs, driven by the issues of\npoor reusability and reproducibility, and highlight their consequent impact on\nenvironmental sustainability. Furthermore, we discuss the fragmented components\nof the AI ecosystem and lack of guiding pathways to best support Open and\nSustainable AI (OSAI) model development. In response, this perspective\nintroduces a practical set of OSAI recommendations directly mapped to over 300\ncomponents of the AI ecosystem. Our work connects researchers with relevant AI\nresources, facilitating the implementation of sustainable, reusable and\ntransparent AI. Built upon life science community consensus and aligned to\nexisting efforts, the outputs of this perspective are designed to aid the\nfuture development of policy and structured pathways for guiding AI\nimplementation.", "authors": ["Gavin Farrell", "Eleni Adamidi", "Rafael Andrade Buono", "Mihail Anton", "Omar Abdelghani Attafi", "Salvador Capella Gutierrez", "Emidio Capriotti", "Leyla Jael Castro", "Davide Cirillo", "Lisa Crossman", "Christophe Dessimoz", "Alexandros Dimopoulos", "Raul Fernandez-Diaz", "Styliani-Christina Fragkouli", "Carole Goble", "Wei Gu", "John M. Hancock", "Alireza Khanteymoori", "Tom Lenaerts", "Fabio G. Liberante", "Peter Maccallum", "Alexander Miguel Monzon", "Magnus Palmblad", "Lucy Poveda", "Ovidiu Radulescu", "Denis C. Shields", "Shoaib Sufi", "Thanasis Vergoulis", "Fotis Psomopoulos", "Silvio C. E. Tosatto"], "published_date": "2025-05-22", "title_zh": "開放且永續的人工智慧：生命科學領域的挑戰、機會與前進之路", "summary_zh": "人工智慧在生命科學領域取得了突破性進展，但快速採用也加劇了研究挑戰，例如可重用性、可再現性差導致信任度下降，並對環境永續性產生影響。研究指出人工智慧生態系統的碎片化以及缺乏指導方針支持開放且永續的人工智慧(OSAI)模型開發。為此，研究提出了實用的OSAI建議，對應於人工智慧生態系統的300多個組件，旨在幫助研究人員連結相關資源，促進永續、可重用和透明的人工智慧應用。這些建議基於生命科學界的共識，並與現有努力方向一致，旨在協助制定未來政策和結構化路徑，以指導人工智慧的實施。", "applications": ["**加速新藥開發：** 透過更容易重現和使用的AI模型，縮短新藥研發週期，更快找到治療疾病的有效藥物。", "**精準醫療：** 基於透明且可解釋的AI模型，醫生能更準確地診斷疾病，並為患者提供個性化的治療方案。", "**永續農業：** 利用AI模型分析作物生長數據，優化灌溉和施肥方案，減少資源浪費，提高農業生產效率。"], "pitch": "生命科學領域的AI應用潛力巨大，但可重現性和透明度問題阻礙了其發展。我們的解決方案透過提供開放且永續的AI模型開發框架，解決這些核心問題。這將帶來以下商業價值：\n\n* **加速AI在生命科學領域的應用：** 提高AI模型的可靠性和可用性，縮短研發週期，加速產品上市。\n* **降低研發成本：** 透過資源共享和標準化流程，減少重複性工作，降低AI模型開發和維護成本。\n* **建立信任：** 提高AI模型的透明度和可解釋性，建立使用者對AI技術的信任，促進其廣泛應用。\n* **創造新的商業模式：** 基於開放的AI平台，可以開發各種增值服務，例如模型訓練、資料分析和諮詢服務。我們正在打造一個可信賴、永續發展的生命科學AI生態系統，為投資者帶來長期回報。", "audio": "audios/2505.16619v1.mp3", "timestamp": "2025-05-25T03:16:04.371463"}
{"query": "Foundation Model", "id": "2505.14975v1", "url": "http://arxiv.org/abs/2505.14975v1", "title": "Flattening Hierarchies with Policy Bootstrapping", "summary": "Offline goal-conditioned reinforcement learning (GCRL) is a promising\napproach for pretraining generalist policies on large datasets of reward-free\ntrajectories, akin to the self-supervised objectives used to train foundation\nmodels for computer vision and natural language processing. However, scaling\nGCRL to longer horizons remains challenging due to the combination of sparse\nrewards and discounting, which obscures the comparative advantages of primitive\nactions with respect to distant goals. Hierarchical RL methods achieve strong\nempirical results on long-horizon goal-reaching tasks, but their reliance on\nmodular, timescale-specific policies and subgoal generation introduces\nsignificant additional complexity and hinders scaling to high-dimensional goal\nspaces. In this work, we introduce an algorithm to train a flat\n(non-hierarchical) goal-conditioned policy by bootstrapping on\nsubgoal-conditioned policies with advantage-weighted importance sampling. Our\napproach eliminates the need for a generative model over the (sub)goal space,\nwhich we find is key for scaling to high-dimensional control in large state\nspaces. We further show that existing hierarchical and bootstrapping-based\napproaches correspond to specific design choices within our derivation. Across\na comprehensive suite of state- and pixel-based locomotion and manipulation\nbenchmarks, our method matches or surpasses state-of-the-art offline GCRL\nalgorithms and scales to complex, long-horizon tasks where prior approaches\nfail.", "authors": ["John L. Zhou", "Jonathan C. Kao"], "published_date": "2025-05-20", "title_zh": "利用策略引導平坦化階層結構", "summary_zh": "離線目標條件強化學習(GCRL)有望在大型無獎勵軌跡數據集上預訓練通用策略，類似於電腦視覺和自然語言處理中用於訓練基礎模型的自我監督目標。然而，由於稀疏獎勵和折扣的組合，GCRL擴展到更長的時間跨度仍然具有挑戰性，這模糊了原始動作相對於遠距離目標的相對優勢。階層式強化學習方法在長時間跨度目標達成任務中取得了強大的實證結果，但其對模組化、特定時間尺度的策略和子目標生成之依賴引入了顯著的額外複雜性，並阻礙了擴展到高維目標空間。在這項工作中，我們引入了一種算法，通過使用優勢加權重要性抽樣來引導子目標條件策略，從而訓練平坦（非階層式）目標條件策略。我們的辦法消除了對(子)目標空間生成模型的需求，我們發現這對於在大狀態空間中擴展到高維控制至關重要。我們進一步表明，現有的基於階層式和引導式的方法對應於我們推導中的特定設計選擇。在全面的基於狀態和基於像素的運動和操縱基準測試套件中，我們的方法與最先進的離線GCRL算法相匹配或超過，並且可以擴展到複雜的、長時間跨度的任務，而先前的方法則失敗。", "applications": ["**自動化機器人組裝線：** 機器人無需人工編程，即可學習複雜的組裝流程，例如將不同零件組裝成完整的產品，即使零件的放置位置不完全一致。", "**個性化健身教練：** AI可以分析用戶的運動數據，並根據用戶的長期目標（例如減肥、增肌）制定個性化的訓練計劃，即使用戶的動作不標準，也能引導他們朝著正確的方向努力。", "**智能家居環境控制：** 系統可以學習用戶的偏好，例如溫度、濕度和光線，並自動調整家居環境，以最大限度地提高用戶的舒適度，即使用戶的行為模式發生變化。"], "pitch": "我們正在開發一種突破性的離線強化學習技術，它能讓AI像人類一樣學習複雜任務，無需大量實時互動和標籤數據。我們的算法擺脫了傳統階層式強化學習的複雜性，通過策略引導，使AI能夠在更廣泛的應用場景中高效學習和執行長程目標。這種技術具有巨大的商業潛力，可以應用於自動化、機器人、醫療保健、金融等領域，大幅降低開發成本，提高效率和智能化水平。我們的團隊擁有多年的AI研究經驗，並擁有堅實的技術基礎。我們正在尋求種子輪投資，以加速產品開發和市場拓展，共同打造下一代智能解決方案。", "audio": "audios/2505.14975v1.mp3", "timestamp": "2025-05-25T03:16:26.388050"}
{"query": "Diffusion Model", "id": "2505.16174v1", "url": "http://arxiv.org/abs/2505.16174v1", "title": "Erased or Dormant? Rethinking Concept Erasure Through Reversibility", "summary": "To what extent does concept erasure eliminate generative capacity in\ndiffusion models? While prior evaluations have primarily focused on measuring\nconcept suppression under specific textual prompts, we explore a complementary\nand fundamental question: do current concept erasure techniques genuinely\nremove the ability to generate targeted concepts, or do they merely achieve\nsuperficial, prompt-specific suppression? We systematically evaluate the\nrobustness and reversibility of two representative concept erasure methods,\nUnified Concept Editing and Erased Stable Diffusion, by probing their ability\nto eliminate targeted generative behaviors in text-to-image models. These\nmethods attempt to suppress undesired semantic concepts by modifying internal\nmodel parameters, either through targeted attention edits or model-level\nfine-tuning strategies. To rigorously assess whether these techniques truly\nerase generative capacity, we propose an instance-level evaluation strategy\nthat employs lightweight fine-tuning to explicitly test the reactivation\npotential of erased concepts. Through quantitative metrics and qualitative\nanalyses, we show that erased concepts often reemerge with substantial visual\nfidelity after minimal adaptation, indicating that current methods suppress\nlatent generative representations without fully eliminating them. Our findings\nreveal critical limitations in existing concept erasure approaches and\nhighlight the need for deeper, representation-level interventions and more\nrigorous evaluation standards to ensure genuine, irreversible removal of\nconcepts from generative models.", "authors": ["Ping Liu", "Chi Zhang"], "published_date": "2025-05-22", "title_zh": "抹除還是休眠？透過可逆性重新思考概念擦除", "summary_zh": "現有的概念擦除技術真的能徹底移除生成模型產生特定概念的能力嗎？這篇論文研究了兩種具代表性的概念擦除方法：Unified Concept Editing 和 Erased Stable Diffusion。研究發現，這些方法實際上並未完全移除概念，僅僅是表面上的抑制。即使經過擦除，這些概念在經過輕微的微調後，仍能重新以高度的視覺保真度生成出來。這表明目前的技術僅僅是抑制了潛在的生成表示，而沒有完全消除它們。因此，需要更深入、更底層的干預手段和更嚴格的評估標準，以確保從生成模型中真正且不可逆地移除概念。", "applications": ["**內容審查強化：** 對於生成式AI模型，例如圖像生成模型，徹底擦除涉及仇恨言論、暴力內容或不適當圖像的概念，避免模型在任何情況下（即使是惡意提示）生成相關內容，確保平台的內容安全性和合規性。", "**智慧財產權保護：** 永久性地移除模型生成侵權內容的能力，例如，防止模型生成與特定品牌形象過於相似的設計，避免版權糾紛，並促進合法合規的使用。", "**個人化體驗優化：** 允許使用者選擇性地擦除或抑制某些概念，以便根據個人偏好定制AI模型的行為。例如，移除可能觸發負面情緒的圖像概念，或者避免模型生成使用者不感興趣的內容，从而提升用户体验。"], "pitch": "我們開發的技術能真正、不可逆地從生成式AI模型中移除特定概念，而非僅僅是表面上的抑制。這解決了目前概念擦除技術的關鍵缺陷，提供了更強大的內容審查、智慧財產權保護和客製化能力。考慮到生成式AI模型的廣泛應用以及對安全、合規和個人化的日益增長的需求，我們的技術具有巨大的商業潛力。我們可以授權這項技術給大型科技公司、內容平台和安全機構，或開發一套獨立的AI安全產品，以確保生成式AI模型的安全和負責使用，創造可觀的營收和社會效益。", "audio": "audios/2505.16174v1.mp3", "timestamp": "2025-05-25T03:16:47.301977"}
{"query": "AI", "id": "2505.16619v1", "url": "http://arxiv.org/abs/2505.16619v1", "title": "Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences", "summary": "Artificial intelligence (AI) has recently seen transformative breakthroughs\nin the life sciences, expanding possibilities for researchers to interpret\nbiological information at an unprecedented capacity, with novel applications\nand advances being made almost daily. In order to maximise return on the\ngrowing investments in AI-based life science research and accelerate this\nprogress, it has become urgent to address the exacerbation of long-standing\nresearch challenges arising from the rapid adoption of AI methods. We review\nthe increased erosion of trust in AI research outputs, driven by the issues of\npoor reusability and reproducibility, and highlight their consequent impact on\nenvironmental sustainability. Furthermore, we discuss the fragmented components\nof the AI ecosystem and lack of guiding pathways to best support Open and\nSustainable AI (OSAI) model development. In response, this perspective\nintroduces a practical set of OSAI recommendations directly mapped to over 300\ncomponents of the AI ecosystem. Our work connects researchers with relevant AI\nresources, facilitating the implementation of sustainable, reusable and\ntransparent AI. Built upon life science community consensus and aligned to\nexisting efforts, the outputs of this perspective are designed to aid the\nfuture development of policy and structured pathways for guiding AI\nimplementation.", "authors": ["Gavin Farrell", "Eleni Adamidi", "Rafael Andrade Buono", "Mihail Anton", "Omar Abdelghani Attafi", "Salvador Capella Gutierrez", "Emidio Capriotti", "Leyla Jael Castro", "Davide Cirillo", "Lisa Crossman", "Christophe Dessimoz", "Alexandros Dimopoulos", "Raul Fernandez-Diaz", "Styliani-Christina Fragkouli", "Carole Goble", "Wei Gu", "John M. Hancock", "Alireza Khanteymoori", "Tom Lenaerts", "Fabio G. Liberante", "Peter Maccallum", "Alexander Miguel Monzon", "Magnus Palmblad", "Lucy Poveda", "Ovidiu Radulescu", "Denis C. Shields", "Shoaib Sufi", "Thanasis Vergoulis", "Fotis Psomopoulos", "Silvio C. E. Tosatto"], "published_date": "2025-05-22", "title_zh": "開放且永續的人工智慧：生命科學領域的挑戰、機會與未來發展之路", "summary_zh": "人工智慧在生命科學領域取得突破性進展，但快速發展也加劇了長期存在的挑戰，例如可重複性差、重用性低，進而影響環境永續性。此外，AI生態系統碎片化，缺乏開放且永續的AI模型開發指導路徑。本研究針對AI生態系統的300多個組件，提出了一套實用的開放且永續AI（OSAI）建議，旨在連接研究人員與相關資源，促進永續、可重複使用和透明的人工智慧實施，並為未來的政策制定和AI實施路徑提供指引。", "applications": ["**加速新藥開發：** 通過開放且可重複使用的AI模型，研究人員可以更快速地識別潛在的藥物靶點，縮短新藥研發週期，降低成本。", "**個性化醫療：** 基於透明且可解釋的AI模型，醫生可以根據患者的基因組、生活方式等信息，制定個性化的治療方案，提高治療效果。", "**農業優化：** 利用開放的AI模型分析作物生長數據、氣候數據等，幫助農民更好地管理農作物，提高產量和效率，同時減少農藥和化肥的使用。"], "pitch": "在生命科學領域，AI正以前所未有的速度發展，帶來巨大的商業機會。然而，缺乏開放性、透明性和可重複性，阻礙了其潛力的充分釋放。我們的研究提供了一套實用的開放且永續AI（OSAI）框架，旨在解決這些痛點，加速AI在生命科學領域的應用。通過投資我們的OSAI平台，您將能夠：1) 參與新藥研發、個性化醫療、農業優化等高增長市場；2) 建立可信賴且合規的AI解決方案，降低風險；3) 提升企業的永續發展形象。我們相信，開放且永續的AI是未來生命科學發展的關鍵，而我們的平台將是您成功的基石。", "audio": "audios/2505.16619v1.mp3", "timestamp": "2025-05-25T04:20:25.451469"}
{"query": "Diffusion Model", "id": "2505.16174v1", "url": "http://arxiv.org/abs/2505.16174v1", "title": "Erased or Dormant? Rethinking Concept Erasure Through Reversibility", "summary": "To what extent does concept erasure eliminate generative capacity in\ndiffusion models? While prior evaluations have primarily focused on measuring\nconcept suppression under specific textual prompts, we explore a complementary\nand fundamental question: do current concept erasure techniques genuinely\nremove the ability to generate targeted concepts, or do they merely achieve\nsuperficial, prompt-specific suppression? We systematically evaluate the\nrobustness and reversibility of two representative concept erasure methods,\nUnified Concept Editing and Erased Stable Diffusion, by probing their ability\nto eliminate targeted generative behaviors in text-to-image models. These\nmethods attempt to suppress undesired semantic concepts by modifying internal\nmodel parameters, either through targeted attention edits or model-level\nfine-tuning strategies. To rigorously assess whether these techniques truly\nerase generative capacity, we propose an instance-level evaluation strategy\nthat employs lightweight fine-tuning to explicitly test the reactivation\npotential of erased concepts. Through quantitative metrics and qualitative\nanalyses, we show that erased concepts often reemerge with substantial visual\nfidelity after minimal adaptation, indicating that current methods suppress\nlatent generative representations without fully eliminating them. Our findings\nreveal critical limitations in existing concept erasure approaches and\nhighlight the need for deeper, representation-level interventions and more\nrigorous evaluation standards to ensure genuine, irreversible removal of\nconcepts from generative models.", "authors": ["Ping Liu", "Chi Zhang"], "published_date": "2025-05-22", "title_zh": "抹除還是休眠？從可逆性的角度重新思考概念抹除", "summary_zh": "這篇論文探討了現有的概念抹除技術，例如用於圖片生成的擴散模型中，是否真的能完全移除特定概念的生成能力，還是僅僅在特定提示詞下抑制了這些概念的生成。研究發現，常用的概念抹除方法，實際上只是讓這些概念進入「休眠」狀態，透過輕量级的微調，就能讓這些被「抹除」的概念重新顯現，而且視覺效果相當好。這表明現有的方法並未真正消除模型中這些概念的潛在表示，需要更深入、針對表示層級的干預，以及更嚴格的評估標準，才能確保真正、不可逆地從生成模型中移除概念。", "applications": ["**內容過濾與審查：** 針對新聞、社群媒體等平台，確保模型生成的圖像不會包含不當內容，如仇恨言論、暴力畫面等。以往認為已抹除的功能可能只是潛伏，此研究有助於開發更有效的過濾系統。", "**保護知識產權：**  確保 AI 模型不會生成侵犯版權的圖像，例如特定角色的風格或特定商標。研究可以幫助開發者徹底移除模型中與版權相關的元素，降低侵權風險。", "**客製化模型訓練：** 在訓練生成模型時，避免模型學習到特定的偏差或不良特徵。例如，避免生成帶有種族歧視或性別歧視的圖像。研究可以協助開發者更精準地控制模型的學習內容，打造更公正的模型。"], "pitch": "現今AI模型越來越強大，但隨之而來的風險，例如產生不當內容或侵犯智慧財產權，也日益增長。我們的研究揭示了現有概念抹除技術的局限性，證明其只能讓特定概念休眠，無法徹底消除。這個發現具有巨大的商業價值。我們將開發更有效的概念抹除技術，為企業提供更安全、可靠的AI模型。這項技術可以應用於內容審查、知識產權保護、客製化模型訓練等多個領域。想像一下，一個能夠完全消除特定風險概念的AI模型，將為企業帶來巨大的競爭優勢，並減少潛在的法律風險。我們的技術將成為AI安全領域的基石，打造一個更值得信賴的AI生態系統。我們尋求創投的資金支持，加速技術開發，並將這項技術推向市場，成為AI安全領域的領導者。", "audio": "audios/2505.16174v1.mp3", "timestamp": "2025-05-25T04:20:46.257354"}
{"query": "AI", "id": "2505.16619v1", "url": "http://arxiv.org/abs/2505.16619v1", "title": "Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences", "summary": "Artificial intelligence (AI) has recently seen transformative breakthroughs\nin the life sciences, expanding possibilities for researchers to interpret\nbiological information at an unprecedented capacity, with novel applications\nand advances being made almost daily. In order to maximise return on the\ngrowing investments in AI-based life science research and accelerate this\nprogress, it has become urgent to address the exacerbation of long-standing\nresearch challenges arising from the rapid adoption of AI methods. We review\nthe increased erosion of trust in AI research outputs, driven by the issues of\npoor reusability and reproducibility, and highlight their consequent impact on\nenvironmental sustainability. Furthermore, we discuss the fragmented components\nof the AI ecosystem and lack of guiding pathways to best support Open and\nSustainable AI (OSAI) model development. In response, this perspective\nintroduces a practical set of OSAI recommendations directly mapped to over 300\ncomponents of the AI ecosystem. Our work connects researchers with relevant AI\nresources, facilitating the implementation of sustainable, reusable and\ntransparent AI. Built upon life science community consensus and aligned to\nexisting efforts, the outputs of this perspective are designed to aid the\nfuture development of policy and structured pathways for guiding AI\nimplementation.", "authors": ["Gavin Farrell", "Eleni Adamidi", "Rafael Andrade Buono", "Mihail Anton", "Omar Abdelghani Attafi", "Salvador Capella Gutierrez", "Emidio Capriotti", "Leyla Jael Castro", "Davide Cirillo", "Lisa Crossman", "Christophe Dessimoz", "Alexandros Dimopoulos", "Raul Fernandez-Diaz", "Styliani-Christina Fragkouli", "Carole Goble", "Wei Gu", "John M. Hancock", "Alireza Khanteymoori", "Tom Lenaerts", "Fabio G. Liberante", "Peter Maccallum", "Alexander Miguel Monzon", "Magnus Palmblad", "Lucy Poveda", "Ovidiu Radulescu", "Denis C. Shields", "Shoaib Sufi", "Thanasis Vergoulis", "Fotis Psomopoulos", "Silvio C. E. Tosatto"], "published_date": "2025-05-22", "title_zh": "開放且永續的AI：生命科學領域的挑戰、機會與未來發展之路", "summary_zh": "AI在生命科學領域取得了突破性進展，但隨之而來的可重複性、可重用性問題正在削弱人們對AI研究成果的信任，並影響環境永續性。 本論文旨在檢視AI生態系統的碎片化問題，並提出一套實用的開放且永續AI (OSAI) 建議，將研究人員與相關AI資源連接起來，促進AI在生命科學領域的永續、可重複和透明應用，為未來的政策制定和AI實施提供指導。", "applications": ["**加速新藥開發：** 透過可重複且透明的AI模型，更快速且可靠地分析生物數據，縮短新藥開發週期，降低開發成本。", "**精準醫療診斷：** 利用開放且永續的AI模型，整合患者的基因組數據、影像資料和臨床病歷，實現更精準的疾病診斷和個人化治療方案。", "**環境保護與生物多樣性監測：** 應用AI分析大量的環境數據，例如動植物分布、水質監測等，預測環境變化趨勢，制定更有效的保護策略。"], "pitch": "我們正面臨生命科學領域AI發展的關鍵轉捩點。雖然AI潛力巨大，但缺乏可重複性和透明度正阻礙其廣泛應用。我們的研究提供一套實用的開放且永續AI (OSAI) 框架，旨在解決這些問題。透過投資我們的OSAI解決方案，您將能: 1) 顯著加速新藥開發和精準醫療，搶佔市場先機；2) 建立一個更具透明度和可信度的AI生態系統，提升企業形象；3) 參與建構更永續的AI發展模式，符合ESG投資趨勢。這不僅是一項技術投資，更是一項對未來醫療和環境永續發展的戰略投資，將帶來巨大的商業價值和社會效益。", "audio": "audios/2505.16619v1.mp3", "timestamp": "2025-05-25T05:12:54.094966"}
{"query": "Foundation Model", "id": "2505.14975v1", "url": "http://arxiv.org/abs/2505.14975v1", "title": "Flattening Hierarchies with Policy Bootstrapping", "summary": "Offline goal-conditioned reinforcement learning (GCRL) is a promising\napproach for pretraining generalist policies on large datasets of reward-free\ntrajectories, akin to the self-supervised objectives used to train foundation\nmodels for computer vision and natural language processing. However, scaling\nGCRL to longer horizons remains challenging due to the combination of sparse\nrewards and discounting, which obscures the comparative advantages of primitive\nactions with respect to distant goals. Hierarchical RL methods achieve strong\nempirical results on long-horizon goal-reaching tasks, but their reliance on\nmodular, timescale-specific policies and subgoal generation introduces\nsignificant additional complexity and hinders scaling to high-dimensional goal\nspaces. In this work, we introduce an algorithm to train a flat\n(non-hierarchical) goal-conditioned policy by bootstrapping on\nsubgoal-conditioned policies with advantage-weighted importance sampling. Our\napproach eliminates the need for a generative model over the (sub)goal space,\nwhich we find is key for scaling to high-dimensional control in large state\nspaces. We further show that existing hierarchical and bootstrapping-based\napproaches correspond to specific design choices within our derivation. Across\na comprehensive suite of state- and pixel-based locomotion and manipulation\nbenchmarks, our method matches or surpasses state-of-the-art offline GCRL\nalgorithms and scales to complex, long-horizon tasks where prior approaches\nfail.", "authors": ["John L. Zhou", "Jonathan C. Kao"], "published_date": "2025-05-20", "title_zh": "利用策略引導扁平化層級結構", "summary_zh": "離線目標導向強化學習 (GCRL) 有潛力利用大規模無獎勵軌跡資料集預訓練通用策略，類似於電腦視覺和自然語言處理中用於訓練基礎模型的自監督目標。然而，由於稀疏獎勵和折扣的結合，使得原始動作相對於遠程目標的相對優勢變得模糊，因此將 GCRL 擴展到更長的時間範圍仍然具有挑戰性。層級強化學習方法在長程目標到達任務中取得了強大的實證結果，但它們對模組化、特定時間尺度的策略和子目標生成的依賴引入了顯著的額外複雜性，並阻礙了擴展到高維目標空間。在這項工作中，我們提出了一種算法，通過使用優勢加權重要性採樣引導子目標導向策略來訓練扁平（非層級）目標導向策略。我們的方法消除了對（子）目標空間生成模型的需求，我們發現這對於在大狀態空間中擴展到高維控制至關重要。我們進一步表明，現有的層級和基於引導的方法對應於我們推導中的特定設計選擇。在全面的基於狀態和像素的運動和操縱基準測試套件中，我們的方法與最先進的離線 GCRL 算法相匹配或超越，並可擴展到以前方法失敗的複雜、長程任務。", "applications": ["**智慧家庭控制：** 機器人可以學習如何透過觀察人類行為來執行複雜的家庭任務，例如準備晚餐、整理房間，無需明確的獎勵信號。例如，觀察到有人打開冰箱、拿出食材、使用爐子等步驟，機器人就能學習準備一道菜。", "**自動駕駛：** 透過大量駕駛數據，訓練自動駕駛系統學習應對各種複雜路況，例如在沒有明確指令的情況下，自主變換車道、超車、避讓行人，並安全到達目的地。系統能根據周圍環境和過去的經驗調整駕駛策略。", "**工業機器人協作：** 在複雜的生產線上，機器人可以通過觀察人類工人的操作，學習執行各種複雜的裝配任務，例如組裝電子產品、汽車零件等，並且能夠與人類工人進行協作，提高生產效率。"], "pitch": "我們開發了一種創新的策略引導技術，可以有效地訓練複雜的長程目標導向機器人，克服了傳統層級強化學習的局限性。這項技術的關鍵優勢在於它不需要手動設計子目標，而是通過觀察大量數據自動學習高效策略。想像一下，一個機器人只需觀察人類行為，就能夠在複雜的環境中執行各種任務。這種能力在智慧家庭、自動駕駛和工業自動化等領域具有巨大的商業潛力。透過我們的方法，可以大幅降低開發和部署複雜機器人系統的成本，加速機器人在各行各業的應用，創造巨大的市場價值。", "audio": "audios/2505.14975v1.mp3", "timestamp": "2025-05-25T05:13:14.310192"}
{"query": "Diffusion Model", "id": "2505.16174v1", "url": "http://arxiv.org/abs/2505.16174v1", "title": "Erased or Dormant? Rethinking Concept Erasure Through Reversibility", "summary": "To what extent does concept erasure eliminate generative capacity in\ndiffusion models? While prior evaluations have primarily focused on measuring\nconcept suppression under specific textual prompts, we explore a complementary\nand fundamental question: do current concept erasure techniques genuinely\nremove the ability to generate targeted concepts, or do they merely achieve\nsuperficial, prompt-specific suppression? We systematically evaluate the\nrobustness and reversibility of two representative concept erasure methods,\nUnified Concept Editing and Erased Stable Diffusion, by probing their ability\nto eliminate targeted generative behaviors in text-to-image models. These\nmethods attempt to suppress undesired semantic concepts by modifying internal\nmodel parameters, either through targeted attention edits or model-level\nfine-tuning strategies. To rigorously assess whether these techniques truly\nerase generative capacity, we propose an instance-level evaluation strategy\nthat employs lightweight fine-tuning to explicitly test the reactivation\npotential of erased concepts. Through quantitative metrics and qualitative\nanalyses, we show that erased concepts often reemerge with substantial visual\nfidelity after minimal adaptation, indicating that current methods suppress\nlatent generative representations without fully eliminating them. Our findings\nreveal critical limitations in existing concept erasure approaches and\nhighlight the need for deeper, representation-level interventions and more\nrigorous evaluation standards to ensure genuine, irreversible removal of\nconcepts from generative models.", "authors": ["Ping Liu", "Chi Zhang"], "published_date": "2025-05-22", "title_zh": "抹除還是休眠？透過可逆性重新思考概念抹除", "summary_zh": "這篇論文探討了在擴散模型中，概念抹除在多大程度上真正消除了生成特定概念的能力。研究發現，現有的概念抹除技術，例如Unified Concept Editing和Erased Stable Diffusion，實際上並沒有完全移除模型生成目標概念的能力，而是只實現了表面的、提示詞特定的抑制。研究者透過輕量級的微調，成功地重新激活了被「抹除」的概念，證明這些概念仍然潛藏在模型中。因此，現有的方法僅僅抑制了潛在的生成表徵，而沒有完全消除它們。這項研究揭示了當前概念抹除方法的局限性，並強調需要更深入、表示層級的干預和更嚴格的評估標準，以確保從生成模型中真正、不可逆地移除概念。", "applications": ["**審查與過濾：** 針對特定敏感詞彙或圖像內容，例如仇恨言論或不適當圖像，進行概念抹除，避免AI生成包含這些內容的圖片。", "**風格轉換與客製化：** 抹除圖片中不需要的風格或元素，例如移除卡通風格，讓AI生成更逼真的圖像；或移除特定品牌Logo，創造更通用的視覺素材。", "**資料增強與模型安全性：** 在訓練AI模型之前，抹除訓練資料中的偏差或敏感資訊，例如抹除人臉識別資料中的種族信息，以提高模型的公平性和安全性。"], "pitch": "現有AI圖像生成模型在概念抹除方面存在嚴重缺陷，表面上的抹除其實只是休眠。這項研究揭示了這個漏洞，並指出了更有效的抹除策略方向。我們的商業價值在於：1. **安全強化：**開發真正有效且不可逆的概念抹除技術，讓AI圖像生成模型不再成為潛在的風險源，確保模型輸出符合法律和道德規範。2. **市場差異化：** 將更安全的AI生成技術授權給其他公司，賦予它們市場競爭力。3. **技術授權與諮詢服務：** 提供概念抹除相關的技術授權和諮詢服務，協助企業在AI應用中降低風險，提升合規性。4. **潛在併購價值：** 在AI安全領域建立領先地位，吸引大型科技公司或政府機構的併購。", "audio": "audios/2505.16174v1.mp3", "timestamp": "2025-05-25T05:13:31.021072"}
{"query": "AI", "id": "2505.16619v1", "url": "http://arxiv.org/abs/2505.16619v1", "title": "Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences", "summary": "Artificial intelligence (AI) has recently seen transformative breakthroughs\nin the life sciences, expanding possibilities for researchers to interpret\nbiological information at an unprecedented capacity, with novel applications\nand advances being made almost daily. In order to maximise return on the\ngrowing investments in AI-based life science research and accelerate this\nprogress, it has become urgent to address the exacerbation of long-standing\nresearch challenges arising from the rapid adoption of AI methods. We review\nthe increased erosion of trust in AI research outputs, driven by the issues of\npoor reusability and reproducibility, and highlight their consequent impact on\nenvironmental sustainability. Furthermore, we discuss the fragmented components\nof the AI ecosystem and lack of guiding pathways to best support Open and\nSustainable AI (OSAI) model development. In response, this perspective\nintroduces a practical set of OSAI recommendations directly mapped to over 300\ncomponents of the AI ecosystem. Our work connects researchers with relevant AI\nresources, facilitating the implementation of sustainable, reusable and\ntransparent AI. Built upon life science community consensus and aligned to\nexisting efforts, the outputs of this perspective are designed to aid the\nfuture development of policy and structured pathways for guiding AI\nimplementation.", "authors": ["Gavin Farrell", "Eleni Adamidi", "Rafael Andrade Buono", "Mihail Anton", "Omar Abdelghani Attafi", "Salvador Capella Gutierrez", "Emidio Capriotti", "Leyla Jael Castro", "Davide Cirillo", "Lisa Crossman", "Christophe Dessimoz", "Alexandros Dimopoulos", "Raul Fernandez-Diaz", "Styliani-Christina Fragkouli", "Carole Goble", "Wei Gu", "John M. Hancock", "Alireza Khanteymoori", "Tom Lenaerts", "Fabio G. Liberante", "Peter Maccallum", "Alexander Miguel Monzon", "Magnus Palmblad", "Lucy Poveda", "Ovidiu Radulescu", "Denis C. Shields", "Shoaib Sufi", "Thanasis Vergoulis", "Fotis Psomopoulos", "Silvio C. E. Tosatto"], "published_date": "2025-05-22", "title_zh": "開放且永續的人工智慧：生命科學領域的挑戰、機遇與前進道路", "summary_zh": "這篇論文探討了人工智慧在生命科學領域的快速發展所帶來的機遇和挑戰。雖然AI極大地提升了生物信息分析能力，但同時也加劇了研究重現性和可重用性的問題，進而影響了研究成果的可信度和環境永續性。論文針對AI生態系統的碎片化問題，提出了開放且永續AI（OSAI）的實用建議，旨在幫助研究人員連結相關AI資源，實現更永續、可重用和透明的AI應用，並為未來的政策制定和AI實施提供指導。", "applications": ["**加速新藥研發：** 利用開放且可重用的AI模型，藥廠能更快速地篩選潛在藥物標靶，降低研發成本，並提高成功率。", "**個性化醫療：** 基於透明且可追溯的AI算法，醫生可以更精確地診斷疾病，制定個性化的治療方案，提升患者療效。", "**精準農業：** 通過開放的AI模型分析土壤、氣候和作物數據，農民可以更有效地管理農田，減少資源浪費，提高農作物產量和品質。"], "pitch": "我們正處於AI在生命科學領域應用爆發的時代，但數據孤島、模型不可解釋以及重現性差等問題嚴重阻礙了行業發展。我們的解決方案是提供一套開放且永續的AI框架(OSAI)，它不僅能解決這些根本問題，還能大幅降低研發成本，加速成果轉化。透過OSAI，我們將建立一個更加透明、高效和可信賴的AI生態系統，為生命科學領域的創新帶來指數級的增長。我們相信，OSAI將成為未來生命科學領域AI應用的黃金標準，具有巨大的市場潛力，並能創造長期可持續的價值。", "audio": "audios/2505.16619v1.mp3", "timestamp": "2025-05-25T06:17:47.022737"}
{"query": "Foundation Model", "id": "2505.14975v1", "url": "http://arxiv.org/abs/2505.14975v1", "title": "Flattening Hierarchies with Policy Bootstrapping", "summary": "Offline goal-conditioned reinforcement learning (GCRL) is a promising\napproach for pretraining generalist policies on large datasets of reward-free\ntrajectories, akin to the self-supervised objectives used to train foundation\nmodels for computer vision and natural language processing. However, scaling\nGCRL to longer horizons remains challenging due to the combination of sparse\nrewards and discounting, which obscures the comparative advantages of primitive\nactions with respect to distant goals. Hierarchical RL methods achieve strong\nempirical results on long-horizon goal-reaching tasks, but their reliance on\nmodular, timescale-specific policies and subgoal generation introduces\nsignificant additional complexity and hinders scaling to high-dimensional goal\nspaces. In this work, we introduce an algorithm to train a flat\n(non-hierarchical) goal-conditioned policy by bootstrapping on\nsubgoal-conditioned policies with advantage-weighted importance sampling. Our\napproach eliminates the need for a generative model over the (sub)goal space,\nwhich we find is key for scaling to high-dimensional control in large state\nspaces. We further show that existing hierarchical and bootstrapping-based\napproaches correspond to specific design choices within our derivation. Across\na comprehensive suite of state- and pixel-based locomotion and manipulation\nbenchmarks, our method matches or surpasses state-of-the-art offline GCRL\nalgorithms and scales to complex, long-horizon tasks where prior approaches\nfail.", "authors": ["John L. Zhou", "Jonathan C. Kao"], "published_date": "2025-05-20", "title_zh": "利用策略引導展平層級結構", "summary_zh": "離線目標條件強化學習 (GCRL) 有望在大型無獎勵軌跡數據集上預訓練通用策略，類似於電腦視覺和自然語言處理中用於訓練基礎模型的自監督目標。然而，由於稀疏獎勵和折扣的結合，使得原始動作在遠期目標方面的相對優勢不明顯，因此將 GCRL 擴展到更長的視野仍然具有挑戰性。分層強化學習方法在長時程目標達成任務上取得了強大的經驗結果，但它們對模組化、特定時間尺度的策略和子目標生成的依賴引入了顯著的額外複雜性，並阻礙了擴展到高維目標空間。在這項工作中，我們引入了一種算法，通過使用優勢加權重要性抽樣對子目標條件策略進行引導，來訓練一個扁平（非分層）的目標條件策略。我們的方法消除了對（子）目標空間上的生成模型的需求，我們發現這對於在大型狀態空間中擴展到高維控制至關重要。我們進一步表明，現有的分層和基於引導的方法對應於我們推導中的特定設計選擇。在全面的基於狀態和基於像素的運動和操縱基準測試中，我們的方法與最先進的離線 GCRL 算法相匹配或超越，並可擴展到先前的算法失敗的複雜的長時程任務。", "applications": ["**機器人流程自動化：** 訓練機器人執行複雜的裝配或倉儲任務，例如在無人倉庫中自動揀選和放置物品，即使任務流程非常長且涉及多個步驟。", "**自動駕駛行為規劃：** 在模擬環境中訓練自動駕駛汽車，使其能夠安全高效地處理長距離駕駛，例如規劃整個城市的路線，並在遇到突發狀況時做出正確決策。", "**遊戲AI：** 訓練遊戲中的 AI 角色執行更複雜的任務，例如策略遊戲中的長期戰略規劃，讓AI能夠學習如何資源分配、軍事調動等，最終贏得勝利。"], "pitch": "我們正在開發一種革命性的強化學習算法，能夠讓機器人和 AI 系統在沒有明確獎勵的情況下，自主學習執行複雜的、長時程的任務。傳統方法需要大量的標註數據和人工干預，而我們的技術則能利用海量未標註數據，像訓練大型語言模型一樣訓練 AI，大幅降低開發成本，並加速 AI 應用落地。想像一下，一個能夠自主學習工廠操作流程的機器人，或者一個能夠在複雜交通環境中安全駕駛的自動駕駛系統，我們的技術將賦予 AI 更強的適應性和通用性，在機器人、自動駕駛、遊戲等領域帶來巨大的商業價值。我們正在尋找投資者，一同開創 AI 的新紀元。", "audio": "audios/2505.14975v1.mp3", "timestamp": "2025-05-25T06:18:04.385509"}
{"query": "Diffusion Model", "id": "2505.16174v1", "url": "http://arxiv.org/abs/2505.16174v1", "title": "Erased or Dormant? Rethinking Concept Erasure Through Reversibility", "summary": "To what extent does concept erasure eliminate generative capacity in\ndiffusion models? While prior evaluations have primarily focused on measuring\nconcept suppression under specific textual prompts, we explore a complementary\nand fundamental question: do current concept erasure techniques genuinely\nremove the ability to generate targeted concepts, or do they merely achieve\nsuperficial, prompt-specific suppression? We systematically evaluate the\nrobustness and reversibility of two representative concept erasure methods,\nUnified Concept Editing and Erased Stable Diffusion, by probing their ability\nto eliminate targeted generative behaviors in text-to-image models. These\nmethods attempt to suppress undesired semantic concepts by modifying internal\nmodel parameters, either through targeted attention edits or model-level\nfine-tuning strategies. To rigorously assess whether these techniques truly\nerase generative capacity, we propose an instance-level evaluation strategy\nthat employs lightweight fine-tuning to explicitly test the reactivation\npotential of erased concepts. Through quantitative metrics and qualitative\nanalyses, we show that erased concepts often reemerge with substantial visual\nfidelity after minimal adaptation, indicating that current methods suppress\nlatent generative representations without fully eliminating them. Our findings\nreveal critical limitations in existing concept erasure approaches and\nhighlight the need for deeper, representation-level interventions and more\nrigorous evaluation standards to ensure genuine, irreversible removal of\nconcepts from generative models.", "authors": ["Ping Liu", "Chi Zhang"], "published_date": "2025-05-22", "title_zh": "抹除還是休眠？透過可逆性重新思考概念抹除", "summary_zh": "這篇論文探討了現有的概念抹除技術，在擴散模型中，是否真的能徹底消除生成特定概念的能力。研究發現，現有的方法大多只是表面上的壓制，通過簡單的微調，被「抹除」的概念就能重新出現，並且具有相當高的視覺逼真度。這意味著現有技術只是抑制了潛在的生成表示，並沒有完全消除它們。論文強調，需要更深入的表示層級干預和更嚴格的評估標準，才能確保真正且不可逆地從生成模型中移除概念。", "applications": ["**內容審查工具增強：** 現有內容審查系統可能誤判已被「抹除」的概念，導致潛在的風險內容被忽略。了解抹除技術的局限性，可以幫助開發更可靠、更精準的內容審查工具。", "**個性化廣告的道德考量：** 如果廣告模型「抹除」了用戶的某些偏好（例如，為了避免冒犯），但這些偏好實際上仍然存在於模型中，那麼重新激活這些偏好的可能性就會引發隱私和操縱方面的問題。", "**藝術創作的安全保障：** 藝術家可以使用生成模型進行創作，但他們可能希望確保模型不會生成某些特定的內容（例如，侵犯版權的圖像）。如果抹除技術不夠可靠，那麼藝術家就可能面臨法律風險。"], "pitch": "各位投資人，我們發現現有的AI內容審查和圖像生成控制技術存在重大漏洞。論文揭示，聲稱已「抹除」的概念，實際上只是被休眠，只需少量微調就能重新激活。這不僅帶來法律和道德風險，也限制了AI技術在商業應用中的可靠性。我們的團隊正在開發下一代概念抹除技術，目標是實現真正、不可逆的概念移除。這將為AI內容審查、個性化廣告、以及藝術創作提供更安全、更可控的環境。想像一下，一個能夠完全消除仇恨言論或不雅圖像的AI系統，其市場潛力巨大！我們相信，通過我們的技術，可以打造更值得信賴的AI生態系統，並在快速增長的AI市場中佔據領先地位。我們正在尋求資金支持，以加速研發進程，並將我們的技術推向市場，成為AI安全領域的領導者。", "audio": "audios/2505.16174v1.mp3", "timestamp": "2025-05-25T06:18:20.693780"}
{"query": "AI", "id": "2505.16619v1", "url": "http://arxiv.org/abs/2505.16619v1", "title": "Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences", "summary": "Artificial intelligence (AI) has recently seen transformative breakthroughs\nin the life sciences, expanding possibilities for researchers to interpret\nbiological information at an unprecedented capacity, with novel applications\nand advances being made almost daily. In order to maximise return on the\ngrowing investments in AI-based life science research and accelerate this\nprogress, it has become urgent to address the exacerbation of long-standing\nresearch challenges arising from the rapid adoption of AI methods. We review\nthe increased erosion of trust in AI research outputs, driven by the issues of\npoor reusability and reproducibility, and highlight their consequent impact on\nenvironmental sustainability. Furthermore, we discuss the fragmented components\nof the AI ecosystem and lack of guiding pathways to best support Open and\nSustainable AI (OSAI) model development. In response, this perspective\nintroduces a practical set of OSAI recommendations directly mapped to over 300\ncomponents of the AI ecosystem. Our work connects researchers with relevant AI\nresources, facilitating the implementation of sustainable, reusable and\ntransparent AI. Built upon life science community consensus and aligned to\nexisting efforts, the outputs of this perspective are designed to aid the\nfuture development of policy and structured pathways for guiding AI\nimplementation.", "authors": ["Gavin Farrell", "Eleni Adamidi", "Rafael Andrade Buono", "Mihail Anton", "Omar Abdelghani Attafi", "Salvador Capella Gutierrez", "Emidio Capriotti", "Leyla Jael Castro", "Davide Cirillo", "Lisa Crossman", "Christophe Dessimoz", "Alexandros Dimopoulos", "Raul Fernandez-Diaz", "Styliani-Christina Fragkouli", "Carole Goble", "Wei Gu", "John M. Hancock", "Alireza Khanteymoori", "Tom Lenaerts", "Fabio G. Liberante", "Peter Maccallum", "Alexander Miguel Monzon", "Magnus Palmblad", "Lucy Poveda", "Ovidiu Radulescu", "Denis C. Shields", "Shoaib Sufi", "Thanasis Vergoulis", "Fotis Psomopoulos", "Silvio C. E. Tosatto"], "published_date": "2025-05-22", "title_zh": "開放且永續的AI：生命科學領域的挑戰、機遇與未來發展方向", "summary_zh": "人工智慧在生命科學領域取得了突破性進展，但快速採用也加劇了研究中長期存在的問題，例如AI研究成果的可重複使用性和可再現性差，導致對AI研究產出的信任度下降，並對環境永續性產生影響。本文探討了AI生態系統的碎片化問題，並針對開放且永續的AI (OSAI) 模型開發，提出了一系列與AI生態系統的300多個組成部分直接相關的實用建議，旨在幫助研究人員找到相關的AI資源，促進永續、可重複使用和透明的AI實施，並為未來的AI政策制定提供指導。", "applications": ["**藥物研發加速：** 利用OSAI原則開發的模型，可以更快速、更可靠地篩選潛在的藥物候選物，縮短藥物開發週期，降低研發成本，並提高新藥上市成功率。", "**精準醫療診斷：** 基於開放且永續的AI模型，可以更準確地分析患者的基因、病歷和生活方式等數據，提供個性化的診斷和治療方案，提高治療效果。", "**環境監測與保護：** 利用OSAI AI模型分析生物數據、環境數據，例如生物多樣性、水質、空氣品質等，更有效地監測環境變化，預測潛在的環境風險，並制定相應的保護措施。"], "pitch": "我們正在構建一個開放、可信賴的AI平台，專注於生命科學領域。該平台基於開放且永續的AI原則，提供一系列可重複使用、透明且可持續的AI模型和工具，旨在加速藥物研發、促進精準醫療、支持環境保護。生命科學領域的AI市場潛力巨大，但缺乏統一的標準和可信賴的平台。我們的平台通過提供高品質、可驗證的AI解決方案，降低行業門檻，促進創新，並確保AI的應用符合倫理和環境要求。我們相信，這個平台將成為生命科學領域AI研究人員和企業的關鍵基礎設施，並為投資者帶來豐厚的回報，尤其是在藥物開發、診斷試劑、農業科技和環境監測等領域。", "audio": "audios/2505.16619v1.mp3", "timestamp": "2025-05-25T07:12:16.330180"}
{"query": "Foundation Model", "id": "2505.14975v1", "url": "http://arxiv.org/abs/2505.14975v1", "title": "Flattening Hierarchies with Policy Bootstrapping", "summary": "Offline goal-conditioned reinforcement learning (GCRL) is a promising\napproach for pretraining generalist policies on large datasets of reward-free\ntrajectories, akin to the self-supervised objectives used to train foundation\nmodels for computer vision and natural language processing. However, scaling\nGCRL to longer horizons remains challenging due to the combination of sparse\nrewards and discounting, which obscures the comparative advantages of primitive\nactions with respect to distant goals. Hierarchical RL methods achieve strong\nempirical results on long-horizon goal-reaching tasks, but their reliance on\nmodular, timescale-specific policies and subgoal generation introduces\nsignificant additional complexity and hinders scaling to high-dimensional goal\nspaces. In this work, we introduce an algorithm to train a flat\n(non-hierarchical) goal-conditioned policy by bootstrapping on\nsubgoal-conditioned policies with advantage-weighted importance sampling. Our\napproach eliminates the need for a generative model over the (sub)goal space,\nwhich we find is key for scaling to high-dimensional control in large state\nspaces. We further show that existing hierarchical and bootstrapping-based\napproaches correspond to specific design choices within our derivation. Across\na comprehensive suite of state- and pixel-based locomotion and manipulation\nbenchmarks, our method matches or surpasses state-of-the-art offline GCRL\nalgorithms and scales to complex, long-horizon tasks where prior approaches\nfail.", "authors": ["John L. Zhou", "Jonathan C. Kao"], "published_date": "2025-05-20", "title_zh": "利用策略引導扁平化層級結構", "summary_zh": "離線目標條件強化學習 (GCRL) 是一種很有潛力的技術，能用大量無獎勵軌跡資料集預訓練通用策略，就像電腦視覺和自然語言處理中使用的自我監督目標訓練基礎模型一樣。然而，由於稀疏獎勵和折扣的結合，使得基本動作在遠程目標上的比較優勢變得模糊，將GCRL擴展到更長的時間範圍仍然具有挑戰性。層級強化學習方法在長時間範圍的目標達成任務上取得了優異的實證成果，但它們對模組化、特定時間尺度的策略和子目標生成的依賴，引入了顯著的額外複雜性，並阻礙了擴展到高維目標空間。在這項工作中，我們引入了一種算法，通過使用優勢加權重要性抽樣在子目標條件策略上進行引導，來訓練扁平（非層級）目標條件策略。 我們的研究方法消除了對（子）目標空間生成模型的需求，我們發現這是擴展到大型狀態空間中的高維控制的關鍵。 我們進一步表明，現有的基於層級和引導的方法對應於我們推導中的特定設計選擇。 在一套全面的基於狀態和基於像素的運動和操作基準測試中，我們的方法與最先進的離線GCRL算法相匹配或超越，並且可以擴展到先前方法失敗的複雜、長時間範圍的任務。", "applications": ["**機器人流程自動化 (RPA):** 訓練機器人完成複雜的工廠組裝任務，即使步驟繁多且目標難以立即實現（例如：精準組裝微型零件）。機器人能夠根據過去的數據學習最佳操作路徑，即使沒有明確的每一步獎勵。", "**自動駕駛：** 訓練自動駕駛車輛在複雜城市環境中導航，即使路線規劃漫長且存在多種可能的路徑（例如：在擁擠的城市中尋找停車位）。車輛可以學習利用先前駕駛數據來優化路線和駕駛行為。", "**個人化健康管理：** 根據用戶的健康數據和生活習慣，訓練AI模型來提供個性化的健康建議和運動計劃。即使長期效果難以立即評估，AI也能學習根據子目標（例如：每日步數、睡眠質量）來引導用戶達到整體健康目標。"], "pitch": "我們開發了一種革命性的強化學習算法，能讓AI在複雜、長時間的任務中表現出色，無需繁瑣的人工分層設計。這就像給AI裝上了一顆更聰明的大腦，能更快、更有效地學習和解決問題。 我們的技術在機器人、自動駕駛和醫療保健等領域具有巨大的應用潛力。想像一下，工廠裡的機器人可以自主完成複雜的組裝工作，無需人工編程；自動駕駛車輛可以更安全、更高效地在城市中導航；個人化的健康管理AI可以幫助人們實現長期的健康目標。我們正在尋找合作夥伴，共同將這項技術推向市場，改變未來的生活和工作方式，創造數十億美元的商業價值。", "audio": "audios/2505.14975v1.mp3", "timestamp": "2025-05-25T07:12:36.629513"}
{"query": "Diffusion Model", "id": "2505.16174v1", "url": "http://arxiv.org/abs/2505.16174v1", "title": "Erased or Dormant? Rethinking Concept Erasure Through Reversibility", "summary": "To what extent does concept erasure eliminate generative capacity in\ndiffusion models? While prior evaluations have primarily focused on measuring\nconcept suppression under specific textual prompts, we explore a complementary\nand fundamental question: do current concept erasure techniques genuinely\nremove the ability to generate targeted concepts, or do they merely achieve\nsuperficial, prompt-specific suppression? We systematically evaluate the\nrobustness and reversibility of two representative concept erasure methods,\nUnified Concept Editing and Erased Stable Diffusion, by probing their ability\nto eliminate targeted generative behaviors in text-to-image models. These\nmethods attempt to suppress undesired semantic concepts by modifying internal\nmodel parameters, either through targeted attention edits or model-level\nfine-tuning strategies. To rigorously assess whether these techniques truly\nerase generative capacity, we propose an instance-level evaluation strategy\nthat employs lightweight fine-tuning to explicitly test the reactivation\npotential of erased concepts. Through quantitative metrics and qualitative\nanalyses, we show that erased concepts often reemerge with substantial visual\nfidelity after minimal adaptation, indicating that current methods suppress\nlatent generative representations without fully eliminating them. Our findings\nreveal critical limitations in existing concept erasure approaches and\nhighlight the need for deeper, representation-level interventions and more\nrigorous evaluation standards to ensure genuine, irreversible removal of\nconcepts from generative models.", "authors": ["Ping Liu", "Chi Zhang"], "published_date": "2025-05-22", "title_zh": "抹除還是休眠？透過可逆性重新思考概念抹除", "summary_zh": "這篇論文探討了概念抹除技術在diffusion models中是否真的消除了生成特定概念的能力。現有的抹除方法通常只針對特定提示詞來評估概念的抑制效果。這篇研究通過探測兩種代表性的抹除方法（Unified Concept Editing和Erased Stable Diffusion）的魯棒性和可逆性，來檢驗它們是否真正移除了生成目標概念的能力。研究發現，這些方法只是抑制了潛在的生成表徵，並沒有完全消除它們。即使经过“抹除”，目标概念在经过轻微调整后仍然可以以相当高的视觉保真度重新出现。這顯示現有方法存在局限性，需要更深層次的干預和更嚴格的評估標準，以確保從生成模型中真正、不可逆地移除概念。", "applications": ["**審查與內容安全：** 自動識別並抑制生成式AI模型中產出仇恨言論、暴力內容或不雅圖片的能力，避免模型被濫用。", "**版權保護與IP安全：** 移除特定藝術家的風格、版權圖像或受保護的商標，防止AI模型生成侵權內容。", "**客製化與風格控制：** 讓使用者可以選擇性地移除或抑制模型中的特定風格或概念，更精確地控制AI生成的結果，例如在設計logo時移除特定字體或元素。"], "pitch": "我們發現現有的概念抹除技術並不可靠，這意味著生成式AI模型仍然存在濫用風險，例如生成有害或侵權內容。我們的研究揭示了這一關鍵漏洞，並為開發真正安全的AI模型提供了方向。我們的技術能更有效地清除模型中的有害概念，降低法律和聲譽風險。同時，它也為AI模型的商業應用打開了新的可能，例如，提供更精確的風格控制選項，滿足不同客戶的需求。投資我們，您將領先一步，在快速發展的AI安全領域佔據優勢地位，打造更安全、更可靠的AI生態系統。我们团队正在开发下一代概念抹除技术，目标是实现真正的不可逆转的抹除，这将成为AI内容生成的安全基石。", "audio": "audios/2505.16174v1.mp3", "timestamp": "2025-05-25T07:12:52.802173"}
