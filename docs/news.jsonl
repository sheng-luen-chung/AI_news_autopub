{"query": "AI", "id": "2505.17021v1", "url": "http://arxiv.org/abs/2505.17021v1", "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "summary": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "authors": ["Sara Ghaboura", "Ketan More", "Wafa Alghallabi", "Omkar Thawakar", "Jorma Laaksonen", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "published_date": "2025-05-22", "title_zh": "ARB：一個全面的阿拉伯語多模態推理基準", "summary_zh": "大型多模態模型(LMMs)越來越強大，評估它們的推理過程也變得更加重要。但現有基準主要集中在英語，忽略了像阿拉伯語這樣具有豐富語言和文化背景的語言。為了解決這個問題，我們推出了全面的阿拉伯語多模態推理基準(ARB)，這是第一個旨在評估阿拉伯語文本和視覺模態中逐步推理的基準。ARB涵蓋11個不同的領域，包括視覺推理、文檔理解、OCR、科學分析和文化詮釋。它包含1,356個多模態樣本，並配有5,119個人工策劃的推理步驟和相應的操作。我們評估了12個最先進的開源和閉源LMMs，發現它們在連貫性、忠實性和文化基礎方面存在持續的挑戰。ARB提供了一個結構化的框架，用於診斷代表性不足語言中的多模態推理，並標誌著邁向包容、透明和具有文化意識的人工智能系統的關鍵一步。我們發布了基準、評分標準和評估套件，以支持未來的研究和可重複性。", "applications": ["**智慧教育：** 將教材圖片和文字結合，讓阿拉伯語學生在學習歷史或科學概念時，能透過模型的逐步推理，更深入理解知識點之間的關聯，例如分析古蘭經中的文本與圖像，輔助宗教研究。", "**智能客服：** 針對阿拉伯語用戶的圖文諮詢，模型可以理解用戶需求並逐步推理，提供更精確的產品建議或問題解答。例如，用戶上傳房屋照片並描述需求，模型可以分析照片風格和文字描述，推薦符合的室內設計方案。", "**新聞分析：** 模型可以分析阿拉伯語新聞文章中的文本和圖片，識別關鍵事件和人物，並根據阿拉伯文化背景進行深入解讀，例如分析政治漫畫中的隱喻和象徵意義。"], "pitch": "ARB基準是阿拉伯語多模態AI的敲門磚。現今LMMs在阿拉伯語理解和推理方面存在顯著差距，這意味著巨大的市場機會。ARB提供了一個客觀的評估標準和豐富的數據集，能加速相關技術的開發和商業化。想像一下，一個能深度理解阿拉伯文化的AI，在智慧教育、內容審核、商業洞察等領域都有著巨大潛力。我們正在打造一個充滿文化智慧的AI生態系統，早期投資將帶來豐厚回報。", "audio": "audios/2505.17021v1.mp3", "timestamp": "2025-05-24T15:19:40.770897"}
{"query": "Foundation Model", "id": "2505.16982v1", "url": "http://arxiv.org/abs/2505.16982v1", "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "published_date": "2025-05-22", "title_zh": "超越關聯性：邁向生物醫學領域的因果大型語言模型代理", "summary_zh": "本文探討如何讓大型語言模型（LLMs）在生物醫學領域具備真正的因果理解能力，而不僅僅依賴關聯性。我們設想一種因果LLM代理，能夠整合多模態數據（文字、圖像、基因組等），並進行基於介入的推理，以推斷因果關係。實現這一目標需要克服諸多挑戰，包括設計安全可控的代理框架、開發嚴格的因果評估基準、整合異質數據源，以及將LLM與結構化知識（知識圖譜）和形式化的因果推斷工具相結合。這種代理有潛力加速藥物發現、實現個人化醫療等變革性應用。本研究旨在促進跨學科合作，結合因果概念和基礎模型，為生物醫學進展開發可靠的AI夥伴。", "applications": ["**精準醫療診斷助手:** 醫生可利用AI分析病人的基因數據、病歷、影像等多模態數據，快速找出疾病的真正病因，制定更有效的治療方案。", "**新藥研發加速器:** AI能夠自動生成藥物作用機制的假設，並模擬藥物在人體內的反應，大幅縮短新藥研發週期，降低研發成本。", "**公共衛生政策模擬器:** 政府可利用AI模擬不同公共衛生政策（例如疫苗接種計劃）對疾病傳播的影響，預測潛在風險，制定更科學合理的政策。"], "pitch": "各位投資人，我們正處於生物醫學AI的黃金時代！現有LLM主要依賴關聯性分析，缺乏真正的因果理解，這限制了它們在生物醫學領域的應用。我們的團隊正在開發基於因果推理的LLM代理，這將是下一代AI的關鍵突破。想像一下，一個能夠預測藥物副作用、診斷罕見疾病、甚至預測公共衛生危機的AI。我們相信，這項技術將徹底改變藥物研發、臨床診斷和公共衛生管理，創造巨大的市場價值。我們不僅提供了一個AI工具，更提供了一個生物醫學領域的變革引擎，等待您的投資來驅動它！", "audio": "audios/2505.16982v1.mp3", "timestamp": "2025-05-24T15:19:59.989021"}
{"query": "Diffusion Model", "id": "2505.17013v1", "url": "http://arxiv.org/abs/2505.17013v1", "title": "When Are Concepts Erased From Diffusion Models?", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "published_date": "2025-05-22", "title_zh": "擴散模型中的概念何時被抹除？", "summary_zh": "概念抹除，也就是選擇性地阻止模型生成特定概念的能力，越來越受到關注。雖然出現了許多方法來應對這個挑戰，但這些方法究竟能多徹底地抹除目標概念仍然不明確。本研究提出了兩個關於擴散模型中抹除機制的概念模型：（一）降低生成目標概念的可能性，以及（二）干擾模型內部的引導機制。為了徹底評估一個概念是否真正從模型中抹除，我們引入了一系列獨立的評估方法，包括對抗攻擊、新穎的探測技術，以及對模型在抹除概念後生成替代方案的分析。我們的結果揭示了最小化副作用和保持對抗性提示的魯棒性之間的權衡。總體而言，我們的工作強調了對擴散模型中的抹除進行全面評估的重要性。", "applications": ["**內容審查與合規性：** 應用於防止生成涉及敏感主題、仇恨言論或侵犯版權的內容，例如自動過濾掉生成式 AI 中的不雅圖片或言論。", "**藝術風格遷移與商業品牌保護：** 允許用戶在模仿特定藝術家風格的同時，避免產生與該藝術家關聯的特定圖像或主題，保護品牌形象，防止AI生成不符品牌調性的內容。", "**數據增強與合成數據安全性：** 在生成用於訓練模型的合成數據時，可以抹除敏感資訊，例如人臉特徵、個人身份資料，保護隱私，同時保留數據的整體結構和特性。"], "pitch": "我們正在開發一種更可靠、可控的概念抹除技術，用於擴散模型。現有技術在抹除特定概念時存在副作用和容易被對抗攻擊繞過的問題。我們的研究揭示了抹除機制的本質，並提供了一套全面的評估框架。這使我們能夠構建更安全、更可定制的生成式AI。商業價值體現在多個方面：首先，它可以幫助企業更好地遵守內容合規法規，降低法律風險。其次，可以保護品牌形象，防止AI生成不符品牌調性的內容。最後，在數據增強和合成數據領域，可以安全地生成大量訓練數據，加速AI模型的開發和部署。我們將打造一個API平台，提供高效、穩定的概念抹除服務，目標是成為生成式AI安全領域的領導者。", "audio": "audios/2505.17013v1.mp3", "timestamp": "2025-05-24T15:20:24.507568"}
{"query": "AI", "id": "2505.17021v1", "url": "http://arxiv.org/abs/2505.17021v1", "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "summary": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "authors": ["Sara Ghaboura", "Ketan More", "Wafa Alghallabi", "Omkar Thawakar", "Jorma Laaksonen", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "published_date": "2025-05-22", "title_zh": "ARB：一個全面的阿拉伯語多模態推理基準", "summary_zh": "論文介紹了一個新的基準測試工具 ARB，用於評估大型多模態模型（LMMs）在阿拉伯語環境下的推理能力。現有的基準測試主要集中在英語，忽略了阿拉伯語等具有豐富語言和文化背景的語言。ARB 涵蓋了視覺推理、文檔理解、OCR、科學分析和文化詮釋等多個領域，包含1356個多模態樣本和5119個人工整理的推理步驟。研究團隊評估了12個最先進的LMMs，發現它們在連貫性、忠實性和文化基礎方面仍存在挑戰。ARB 提供了一個結構化的框架，用於診斷在代表性不足的語言中的多模態推理，並朝著包容性、透明性和具有文化意識的人工智慧系統邁出了重要一步。該基準、評分標準和評估套件已公開發布。", "applications": ["**智能客服：** 應用於理解阿拉伯語客戶的語音和圖像問題，提供更準確和文化的相關的回應，例如：識別客戶拍攝的水果照片，並用阿拉伯語回答關於水果營養和產地等問題。", "**文化遺產保護：** 幫助解讀阿拉伯語古籍文獻和文物圖片，促進文化遺產的數位化和研究。 例如，分析古蘭經手稿的圖片，並自動提取重要段落，進行翻譯和註釋。", "**教育應用：** 用於開發阿拉伯語的互動式學習工具，提供多模態的教學內容，例如：根據學生提交的阿拉伯語作文圖片，自動評估其語法、文法和風格，並提供個性化建議。"], "pitch": "ARB 作為首個專注於阿拉伯語多模態推理的基準，解決了市場上對於非英語環境下 AI 評估的巨大缺口。 我們將提供一套經過驗證的工具，幫助企業和研究機構開發更智能、更符合文化背景的阿拉伯語 AI 應用。 數據集的稀缺性和專業性構成天然壁壘，有利於佔領市場先機。 潛在的商業模式包括：基準測試服務、AI模型評估和優化諮詢、特定領域的阿拉伯語AI解決方案（如智能客服、教育、文化遺產保護等）。 隨著中東和北非地區AI市場的快速增長，ARB具有巨大的商業價值。", "audio": "audios/2505.17021v1.mp3", "timestamp": "2025-05-24T15:38:43.259354"}
{"query": "Foundation Model", "id": "2505.16982v1", "url": "http://arxiv.org/abs/2505.16982v1", "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "published_date": "2025-05-22", "title_zh": "超越關聯性：朝向生物醫學領域的因果大型語言模型代理", "summary_zh": "這篇論文探討了如何讓大型語言模型（LLMs）在生物醫學領域具備真正的因果理解能力，而不僅僅是依賴關聯性。它提出了因果LLM代理的概念，這些代理能整合多模態數據（文字、圖片、基因組等），並進行基於干預的推理來推斷因果關係。開發這種代理需要克服一些挑戰，例如設計安全可控的代理框架、建立嚴謹的因果評估基準、整合異質數據源，以及將LLMs與結構化知識（知識圖譜）和正式的因果推斷工具結合。這樣的代理有潛力帶來變革性的機會，例如加速藥物發現和實現個性化醫療。", "applications": ["**個性化藥物反應預測：** 根據病患的基因組、病史、生活習慣等多維度資料，預測他們對不同藥物的反應，避免無效治療或不良反應。", "**新型療法探索：** 通過模擬不同治療方案對疾病進程的影響，找出潛在的藥物靶點或干預策略，加速新藥研發和療法開發。", "**臨床決策輔助：** 協助醫生評估病患病情，提供更精確的診斷建議，並根據因果關係模型，預測不同治療方案的可能結果，輔助決策。"], "pitch": "我們正在開發新一代的AI藥物研發平台，核心是具備因果推理能力的大型語言模型。相較於目前僅能分析關聯性的AI，我們的技術能更準確地預測藥物效果，大幅縮短研發時程，降低失敗風險，並實現精準醫療。 我們預計能顯著提升藥物開發的成功率，為製藥公司帶來數十億美元的潛在收益。 這項技術的商業價值在於大幅降低研發成本，加速藥物上市，並且為患者提供更有效的治療方案。 想像一下，一個AI能精準預測病患對特定藥物的反應，避免無效治療，這將對醫療產業帶來革命性的影響。", "audio": "audios/2505.16982v1.mp3", "timestamp": "2025-05-24T15:38:58.221274"}
{"query": "Diffusion Model", "id": "2505.17013v1", "url": "http://arxiv.org/abs/2505.17013v1", "title": "When Are Concepts Erased From Diffusion Models?", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "published_date": "2025-05-22", "title_zh": "擴散模型中的概念何時會被抹除？", "summary_zh": "概念抹除，也就是選擇性地阻止模型生成特定概念的能力，正受到越來越多的關注。儘管出現了各種方法來應對這一挑戰，但這些方法究竟能多徹底地抹除目標概念仍然不明朗。本研究提出了兩個關於擴散模型中抹除機制的概念模型：（一）降低生成目標概念的可能性，以及（二）干擾模型內部的引導機制。為了全面評估一個概念是否真正從模型中被抹除，我們引入了一套獨立的評估方法，包括對抗性攻擊、新型探測技術，以及分析模型在抹除概念後的替代生成結果。研究結果揭示了最小化副作用和維持對抗性提示的穩健性之間的緊張關係。總體而言，我們的工作強調了在擴散模型中進行概念抹除時，全面評估的重要性。", "applications": ["**內容安全過濾：** 針對仇恨言論、暴力內容等敏感詞彙和圖像，從AI生成內容中徹底抹除，避免生成不當內容。", "**個性化產品設計：** 在設計過程中抹除特定的設計風格或品牌元素，例如，在生成Logo時避免與現有品牌過於相似，確保原創性。", "**醫療影像匿名化：** 在醫療影像數據集中，抹除人臉、紋身等個人識別信息，同時保留醫療診斷所需的關鍵特徵，保護患者隱私。"], "pitch": "各位投資人，想像一下，AI創作內容充斥著版權爭議、仇恨言論和侵犯隱私的風險。我們團隊的研究突破性地解決了這個問題，開發出能精準抹除AI模型中特定概念的技術。這不僅能確保內容安全合規，還能賦予AI更強大的可控性，催生出個性化定製和數據隱私保護的新應用。從內容審核到設計創新，再到醫療數據安全，我們的技術擁有廣闊的市場前景。我們需要您的投資，將這項技術商業化，引領下一代安全、可信賴的AI內容創作，成為AI時代的守門人，佔據市場領導地位。", "audio": "audios/2505.17013v1.mp3", "timestamp": "2025-05-24T15:39:20.981673"}
{"query": "AI", "id": "2505.17021v1", "url": "http://arxiv.org/abs/2505.17021v1", "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "summary": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "authors": ["Sara Ghaboura", "Ketan More", "Wafa Alghallabi", "Omkar Thawakar", "Jorma Laaksonen", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "published_date": "2025-05-22", "title_zh": "ARB：一個全面的阿拉伯語多模態推理基準", "summary_zh": "大型多模態模型（LMMs）越來越強大，評估其推理過程變得重要。但現有基準主要針對英語，忽略了阿拉伯語等具有豐富語言和文化背景的語言。為此，我們推出了全面的阿拉伯語多模態推理基準（ARB），這是第一個旨在評估阿拉伯語中跨文本和視覺模態逐步推理的基準。ARB涵蓋11個不同的領域，包括視覺推理、文檔理解、OCR、科學分析和文化詮釋。它包含1,356個多模態樣本，配有5,119個人工整理的推理步驟和相應的操作。我們評估了12個最先進的開源和閉源LMM，發現它們在連貫性、忠實性和文化基礎方面仍存在挑戰。ARB提供了一個結構化的框架，用於診斷代表性不足語言中的多模態推理，標誌著邁向包容性、透明和具有文化意識的AI系統的關鍵一步。我們發布了基準、評分標準和評估套件，以支持未來的研究和可重複性。", "applications": ["**自動阿拉伯語文檔審閱與摘要:** 自動理解並總結阿拉伯語的法律、科學或歷史文檔，並能解釋其背後的邏輯和文化含義，例如審核伊斯蘭教法相關合約。", "**視覺內容的阿拉伯語文化適配:** 能夠理解圖像或影片中的阿拉伯語文化元素，並根據目標受眾進行適當的修改或翻譯，例如將西方廣告翻譯成阿拉伯語時，確保符合當地文化規範。", "**阿拉伯語教材輔助教學:** 分析阿拉伯語教材中的圖片、文字，並提供逐步的解釋和推理，幫助學生更好地理解和掌握知識，例如解釋古蘭經或阿拉伯文學作品中的隱喻和文化背景。"], "pitch": "ARB是第一個針對阿拉伯語多模態推理的綜合性基準，解決了AI模型在理解阿拉伯語文化和上下文方面的巨大缺口。目前市場上缺乏有效的阿拉伯語AI解決方案，而ARB的出現將加速相關技術的發展，為企業提供在阿拉伯語市場開展業務的關鍵工具。投資ARB的相關研究和應用，將有助於開發出更智能、更可靠、更符合文化需求的AI產品，並在快速增長的阿拉伯語市場中獲得巨大的商業價值。我們正處於構建下一個十億用戶AI的風口浪尖，而阿拉伯語AI將是其中的重要一環。", "audio": "audios/2505.17021v1.mp3", "timestamp": "2025-05-24T16:01:24.302023"}
{"query": "Foundation Model", "id": "2505.16982v1", "url": "http://arxiv.org/abs/2505.16982v1", "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "published_date": "2025-05-22", "title_zh": "超越相關性：邁向生物醫學領域的因果大型語言模型代理", "summary_zh": "目前的大型語言模型雖然在生物醫學領域展現潛力，但缺乏真正的因果理解，主要依賴相關性。本文提出一個願景，設想具備因果理解能力的大型語言模型代理，它們能整合多模態數據（文本、圖像、基因組等），並執行基於干預的推理，以推斷因果關係。要實現這一目標，需要克服關鍵挑戰：設計安全、可控的代理框架；開發嚴格的因果評估基準；整合異質數據源；以及將大型語言模型與結構化知識（知識圖譜）和形式化的因果推理工具協同結合。這樣的代理可以釋放變革性的機會，包括通過自動化的假設生成和模擬加速藥物發現，並通過針對患者的因果模型實現個性化醫療。此研究議程旨在促進跨學科合作，將因果概念和基礎模型結合起來，從而開發出可靠的AI合作夥伴，推動生物醫學的進步。", "applications": ["**加速藥物發現：** AI 代理可以自動生成藥物開發的假設，並模擬藥物在不同生理環境下的作用，大幅縮短研發週期。", "**個性化醫療方案：** 根據患者的基因、生活習慣、病史等多維數據，建立個性化的因果模型，預測治療效果，制定更精準的醫療方案。", "**公共衛生政策模擬：** 在疫情爆發等緊急情況下，模擬不同干預措施（例如封鎖、疫苗接種）對疫情傳播的影響，為決策者提供科學依據。"], "pitch": "我們正在構建生物醫學領域的下一代AI引擎：因果大型語言模型代理。與傳統依賴相關性的AI不同，我們的技術能真正理解因果關係，從而做出更準確的預測和更合理的決策。想像一下，一種AI能夠自動發現新藥靶點，為每位患者量身定制治療方案，並在公共衛生危機中提供最佳干預策略。這不僅能大幅降低藥物研發成本，還能顯著提高治療效果，並為公共衛生安全提供強有力的保障。我們擁有一支跨學科的頂尖團隊，正在攻克關鍵技術挑戰，並已取得初步成果。 我們相信，這項技術具有巨大的市場潛力，將徹底改變生物醫學領域，為投資者帶來豐厚的回報。現在加入我們，一起開創生物醫學AI的未來！", "audio": "audios/2505.16982v1.mp3", "timestamp": "2025-05-24T16:01:42.349579"}
{"query": "Diffusion Model", "id": "2505.17013v1", "url": "http://arxiv.org/abs/2505.17013v1", "title": "When Are Concepts Erased From Diffusion Models?", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "published_date": "2025-05-22", "title_zh": "擴散模型中的概念何時被抹除？", "summary_zh": "概念抹除，也就是選擇性地阻止模型生成特定概念的能力，引起了越來越多的關注，並且出現了各種解決這個挑戰的方法。然而，這些方法抹除目標概念的徹底程度仍然不清楚。我們首先提出了兩個擴散模型中抹除機制的概念模型：(i) 降低生成目標概念的可能性，以及 (ii) 干擾模型內部的引導機制。為了徹底評估一個概念是否真正從模型中抹除，我們引入了一套獨立的評估方法。我們的評估框架包括對抗性攻擊、新穎的探測技術，以及對模型在抹除概念後產生的替代生成的分析。我們的結果揭示了最小化副作用和保持對對抗性提示的魯棒性之間的張力。總體而言，我們的研究強調了對擴散模型中的抹除進行全面評估的重要性。", "applications": ["**兒童安全內容生成：** 可以移除模型生成兒童不宜的內容，例如暴力、性暗示等，確保產出的影像適合兒童觀看，打造更安全的內容生態。", "**保護智慧財產權：** 移除模型生成涉及特定品牌或角色的內容，避免侵權行為，協助企業保護自己的智慧財產權。", "**醫療影像處理：** 在醫療影像中移除可能洩漏病人隱私的個人資訊或敏感區域，例如臉部、紋身等，在保護病人隱私的同時，也能進行影像分析和模型訓練。"], "pitch": "我們正在解決AI安全和道德的根本問題：如何可靠地從AI模型中移除特定概念，防止其產生有害或不當內容。現有的「概念抹除」方法效果不一，我們提供了更嚴格的評估標準和技術，確保抹除的徹底性。這項技術的商業價值在於：1. **合規性與信任：** 協助企業符合日益嚴格的AI監管要求，建立使用者對AI內容的信任。2. **降低風險：** 減少AI模型產生有害內容造成的法律責任和聲譽損害。3. **差異化競爭：** 為內容生成平台提供更安全、更可靠的服務，在市場上脫穎而出。我們正在尋求投資，以擴展我們的評估框架，開發更有效的抹除技術，並將其商業化，成為AI安全領域的領導者。", "audio": "audios/2505.17013v1.mp3", "timestamp": "2025-05-24T16:01:59.997130"}
{"query": "AI", "id": "2505.17021v1", "url": "http://arxiv.org/abs/2505.17021v1", "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "summary": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "authors": ["Sara Ghaboura", "Ketan More", "Wafa Alghallabi", "Omkar Thawakar", "Jorma Laaksonen", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "published_date": "2025-05-22", "title_zh": "ARB：一個全面的阿拉伯語多模態推理基準測試", "summary_zh": "本論文提出了一個名為 ARB 的全新基準測試，專門用於評估大型多模態模型 (LMM) 在阿拉伯語環境下的推理能力。現有基準測試大多集中在英語，忽略了像阿拉伯語這樣具有豐富語言和文化背景的語言。ARB 涵蓋視覺推理、文檔理解、光學字元識別、科學分析和文化詮釋等11個不同領域，包含1356個多模態樣本和5119個人工策劃的推理步驟。研究團隊評估了12個最先進的 LMM，發現它們在連貫性、忠實性和文化基礎方面仍存在挑戰。ARB 提供了一個結構化的框架，用於診斷在代表性不足的語言中的多模態推理能力，並標誌著邁向包容性、透明性和具有文化意識的 AI 系統的關鍵一步。研究團隊公開了基準測試、評分標準和評估工具，以支持未來的研究和可再現性。", "applications": ["**智能阿拉伯語教學系統：** 利用 ARB 訓練的 LMM 可以根據學生提供的文本和圖像，提供個性化的學習反饋，並解釋其中涉及的阿拉伯文化元素，從而提升學習效率和趣味性。", "**多語種文檔處理與翻譯：** 應用於大規模阿拉伯語文檔的自動翻譯，不僅能準確翻譯文字，還能理解圖像和圖表，並根據阿拉伯文化背景進行調整，確保翻譯結果更符合當地習慣。", "**智慧城市中的文化遺產保護：** 通過分析歷史圖片、文檔和地理數據，LMM 可以自動識別和保護阿拉伯世界的文化遺址，並生成互動式展覽內容，讓遊客更深入地了解當地歷史和文化。"], "pitch": "ARB 填補了大型多模態模型在阿拉伯語領域的評估空白，解決了目前 AI 模型缺乏文化理解和推理能力的問題。這個基準測試對於開發能夠有效處理阿拉伯語環境下文本和圖像的 AI 系統至關重要。基於 ARB 的技術具有廣泛的商業價值，例如提升阿拉伯語客戶服務的質量、加速阿拉伯語文檔的數位化進程，以及促進阿拉伯文化遺產的保護和傳播。通過投資基於 ARB 基準開發的 AI 解決方案，我們可以搶佔阿拉伯語多模態 AI 市場的先機，並在快速增長的阿拉伯數字經濟中獲得可觀的回報。", "audio": "audios/2505.17021v1.mp3", "timestamp": "2025-05-24T16:05:27.675474"}
{"query": "Foundation Model", "id": "2505.16982v1", "url": "http://arxiv.org/abs/2505.16982v1", "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "published_date": "2025-05-22", "title_zh": "超越相關性：邁向生物醫學領域的因果大型語言模型代理", "summary_zh": "這篇論文探討如何讓大型語言模型（LLMs）在生物醫學領域具備真正的因果理解能力，而不僅僅是仰賴相關性。作者設想一種因果LLM代理，它能整合多模態數據（文本、圖像、基因組數據等），並通過基於干預的推理來推斷因果關係。要實現這一目標，需要克服安全可控的代理框架設計、嚴格的因果評估基準開發、異構數據源整合，以及將LLMs與結構化知識（知識圖譜）和形式因果推理工具協同結合等挑戰。這種代理有望加速藥物發現、實現個性化醫療，並成為生物醫學研究中可靠的AI夥伴。", "applications": ["**藥物開發加速器：** 因果LLM代理可以自動生成和模擬藥物作用假設，大幅縮短藥物研發周期。", "**精準醫療專家：** 根據患者的個性化數據，構建個體化的因果模型，幫助醫生制定更有效的治療方案。", "**疾病風險預測工具：** 整合基因組、生活習慣等多維度數據，預測個體患病風險，提前進行預防干預。"], "pitch": "我們正在構建下一代生物醫學AI，它不僅僅是信息彙總工具，而是具備因果推理能力的智能代理。這將徹底改變藥物研發、個性化醫療和疾病預防等領域。試想一下，一個能夠自動發現新藥靶點、為每位患者量身定制治療方案的AI助手。我們需要資金來克服技術挑戰，建立可靠、安全的因果LLM代理，並将其商業化。回報將是巨大的：更快的藥物研發速度、更精準的醫療方案和更健康的社會。這不僅僅是一個投資，更是一次對未來醫療的佈局。", "audio": "audios/2505.16982v1.mp3", "timestamp": "2025-05-24T16:05:44.781587"}
{"query": "Diffusion Model", "id": "2505.17013v1", "url": "http://arxiv.org/abs/2505.17013v1", "title": "When Are Concepts Erased From Diffusion Models?", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "published_date": "2025-05-22", "title_zh": "擴散模型中的概念何時被抹除？", "summary_zh": "概念抹除，也就是選擇性地阻止模型生成特定概念的能力，正引起越來越多的關注，並出現了各種方法來應對這一挑戰。然而，這些方法究竟能多徹底地抹除目標概念，仍然不明朗。 本文首先針對擴散模型中的抹除機制提出了兩個概念模型：（i）降低生成目標概念的可能性，以及（ii）干擾模型的內部引導機制。 為了徹底評估一個概念是否真正從模型中被抹除，我們引入了一套獨立的評估方法。 我們的評估框架包括對抗性攻擊、新穎的探測技術，以及對模型在抹除概念後產生的替代性生成的分析。 我們的研究結果揭示了最小化副作用和保持對抗性提示的穩健性之間的權衡。 總體而言，我們的研究強調了對擴散模型中抹除效果進行全面評估的重要性。", "applications": ["**內容審查與保護：** 防止生成涉及暴力、仇恨言論或不適當內容的圖像，例如自動過濾掉兒童不宜的圖像或避免生成特定政治人物的虛假圖片。", "**個人化體驗優化：** 根據用戶偏好，動態過濾掉用戶不喜歡或觸發負面情緒的概念，例如在遊戲中移除特定敵人類型，或在廣告中排除特定品牌。", "**設計與創作控制：** 在設計過程中，移除設計師不希望出現的元素或風格，例如在建築設計中避免特定建築風格，或在產品設計中排除特定材料。"], "pitch": "我們解決的是AI生成內容領域的核心信任問題：如何有效控制模型的生成內容，避免產生有害、不適當或不符合需求的結果。我們的研究揭示了現有概念抹除方法的局限性，並提供了更全面的評估框架。這使得我們能夠開發更有效、更安全的AI生成工具，應用於內容審查、個人化體驗和創意設計等領域。想像一下，一個能夠完全受控的AI內容生成引擎，它能夠在滿足用戶需求的同時，有效避免產生有害內容，這將極大地提升AI在各行業的應用價值，並為我們帶來巨大的商業機會。", "audio": "audios/2505.17013v1.mp3", "timestamp": "2025-05-24T16:06:09.636884"}
