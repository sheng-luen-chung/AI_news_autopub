{"query": "AI", "id": "2505.17021v1", "url": "http://arxiv.org/abs/2505.17021v1", "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "summary": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "authors": ["Sara Ghaboura", "Ketan More", "Wafa Alghallabi", "Omkar Thawakar", "Jorma Laaksonen", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "published_date": "2025-05-22", "title_zh": "ARB：一個全面的阿拉伯語多模態推理基準", "summary_zh": "大型多模態模型(LMMs)越來越強大，評估它們的推理過程也變得更加重要。但現有基準主要集中在英語，忽略了像阿拉伯語這樣具有豐富語言和文化背景的語言。為了解決這個問題，我們推出了全面的阿拉伯語多模態推理基準(ARB)，這是第一個旨在評估阿拉伯語文本和視覺模態中逐步推理的基準。ARB涵蓋11個不同的領域，包括視覺推理、文檔理解、OCR、科學分析和文化詮釋。它包含1,356個多模態樣本，並配有5,119個人工策劃的推理步驟和相應的操作。我們評估了12個最先進的開源和閉源LMMs，發現它們在連貫性、忠實性和文化基礎方面存在持續的挑戰。ARB提供了一個結構化的框架，用於診斷代表性不足語言中的多模態推理，並標誌著邁向包容、透明和具有文化意識的人工智能系統的關鍵一步。我們發布了基準、評分標準和評估套件，以支持未來的研究和可重複性。", "applications": ["**智慧教育：** 將教材圖片和文字結合，讓阿拉伯語學生在學習歷史或科學概念時，能透過模型的逐步推理，更深入理解知識點之間的關聯，例如分析古蘭經中的文本與圖像，輔助宗教研究。", "**智能客服：** 針對阿拉伯語用戶的圖文諮詢，模型可以理解用戶需求並逐步推理，提供更精確的產品建議或問題解答。例如，用戶上傳房屋照片並描述需求，模型可以分析照片風格和文字描述，推薦符合的室內設計方案。", "**新聞分析：** 模型可以分析阿拉伯語新聞文章中的文本和圖片，識別關鍵事件和人物，並根據阿拉伯文化背景進行深入解讀，例如分析政治漫畫中的隱喻和象徵意義。"], "pitch": "ARB基準是阿拉伯語多模態AI的敲門磚。現今LMMs在阿拉伯語理解和推理方面存在顯著差距，這意味著巨大的市場機會。ARB提供了一個客觀的評估標準和豐富的數據集，能加速相關技術的開發和商業化。想像一下，一個能深度理解阿拉伯文化的AI，在智慧教育、內容審核、商業洞察等領域都有著巨大潛力。我們正在打造一個充滿文化智慧的AI生態系統，早期投資將帶來豐厚回報。", "audio": "audios/2505.17021v1.mp3", "timestamp": "2025-05-24T15:19:40.770897"}
{"query": "Foundation Model", "id": "2505.16982v1", "url": "http://arxiv.org/abs/2505.16982v1", "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "published_date": "2025-05-22", "title_zh": "超越關聯性：邁向生物醫學領域的因果大型語言模型代理", "summary_zh": "本文探討如何讓大型語言模型（LLMs）在生物醫學領域具備真正的因果理解能力，而不僅僅依賴關聯性。我們設想一種因果LLM代理，能夠整合多模態數據（文字、圖像、基因組等），並進行基於介入的推理，以推斷因果關係。實現這一目標需要克服諸多挑戰，包括設計安全可控的代理框架、開發嚴格的因果評估基準、整合異質數據源，以及將LLM與結構化知識（知識圖譜）和形式化的因果推斷工具相結合。這種代理有潛力加速藥物發現、實現個人化醫療等變革性應用。本研究旨在促進跨學科合作，結合因果概念和基礎模型，為生物醫學進展開發可靠的AI夥伴。", "applications": ["**精準醫療診斷助手:** 醫生可利用AI分析病人的基因數據、病歷、影像等多模態數據，快速找出疾病的真正病因，制定更有效的治療方案。", "**新藥研發加速器:** AI能夠自動生成藥物作用機制的假設，並模擬藥物在人體內的反應，大幅縮短新藥研發週期，降低研發成本。", "**公共衛生政策模擬器:** 政府可利用AI模擬不同公共衛生政策（例如疫苗接種計劃）對疾病傳播的影響，預測潛在風險，制定更科學合理的政策。"], "pitch": "各位投資人，我們正處於生物醫學AI的黃金時代！現有LLM主要依賴關聯性分析，缺乏真正的因果理解，這限制了它們在生物醫學領域的應用。我們的團隊正在開發基於因果推理的LLM代理，這將是下一代AI的關鍵突破。想像一下，一個能夠預測藥物副作用、診斷罕見疾病、甚至預測公共衛生危機的AI。我們相信，這項技術將徹底改變藥物研發、臨床診斷和公共衛生管理，創造巨大的市場價值。我們不僅提供了一個AI工具，更提供了一個生物醫學領域的變革引擎，等待您的投資來驅動它！", "audio": "audios/2505.16982v1.mp3", "timestamp": "2025-05-24T15:19:59.989021"}
{"query": "Diffusion Model", "id": "2505.17013v1", "url": "http://arxiv.org/abs/2505.17013v1", "title": "When Are Concepts Erased From Diffusion Models?", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "published_date": "2025-05-22", "title_zh": "擴散模型中的概念何時被抹除？", "summary_zh": "概念抹除，也就是選擇性地阻止模型生成特定概念的能力，越來越受到關注。雖然出現了許多方法來應對這個挑戰，但這些方法究竟能多徹底地抹除目標概念仍然不明確。本研究提出了兩個關於擴散模型中抹除機制的概念模型：（一）降低生成目標概念的可能性，以及（二）干擾模型內部的引導機制。為了徹底評估一個概念是否真正從模型中抹除，我們引入了一系列獨立的評估方法，包括對抗攻擊、新穎的探測技術，以及對模型在抹除概念後生成替代方案的分析。我們的結果揭示了最小化副作用和保持對抗性提示的魯棒性之間的權衡。總體而言，我們的工作強調了對擴散模型中的抹除進行全面評估的重要性。", "applications": ["**內容審查與合規性：** 應用於防止生成涉及敏感主題、仇恨言論或侵犯版權的內容，例如自動過濾掉生成式 AI 中的不雅圖片或言論。", "**藝術風格遷移與商業品牌保護：** 允許用戶在模仿特定藝術家風格的同時，避免產生與該藝術家關聯的特定圖像或主題，保護品牌形象，防止AI生成不符品牌調性的內容。", "**數據增強與合成數據安全性：** 在生成用於訓練模型的合成數據時，可以抹除敏感資訊，例如人臉特徵、個人身份資料，保護隱私，同時保留數據的整體結構和特性。"], "pitch": "我們正在開發一種更可靠、可控的概念抹除技術，用於擴散模型。現有技術在抹除特定概念時存在副作用和容易被對抗攻擊繞過的問題。我們的研究揭示了抹除機制的本質，並提供了一套全面的評估框架。這使我們能夠構建更安全、更可定制的生成式AI。商業價值體現在多個方面：首先，它可以幫助企業更好地遵守內容合規法規，降低法律風險。其次，可以保護品牌形象，防止AI生成不符品牌調性的內容。最後，在數據增強和合成數據領域，可以安全地生成大量訓練數據，加速AI模型的開發和部署。我們將打造一個API平台，提供高效、穩定的概念抹除服務，目標是成為生成式AI安全領域的領導者。", "audio": "audios/2505.17013v1.mp3", "timestamp": "2025-05-24T15:20:24.507568"}
